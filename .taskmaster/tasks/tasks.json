{
  "master": {
    "tasks": [
      {
        "id": 11,
        "title": "[BFS-4] signing-service Multicall3 배치 전송 기능 구현",
        "description": "ERC20 토큰 배치 전송을 위한 Multicall3 통합 기능 구현",
        "jiraKey": "BFS-4",
        "details": "Multicall3 컨트랙트 주소 설정 (Polygon: 0xcA11bde05977b3631167028862bE2a173976CA11), MulticallService 클래스 구현으로 여러 ERC20 전송을 하나의 트랜잭션으로 배치 처리, TransactionSigner에 signBatchTransaction() 메서드 추가, WithdrawalRequest 모델에 type 필드 추가 ('SINGLE' | 'BATCH'), ABI 인코딩 및 calldata 생성 로직 구현, 배치 크기 최적화 (가스 한도 내에서 최대 전송 수 계산)",
        "testStrategy": "Multicall3 컨트랙트 호출 테스트, 배치 전송 가스 계산 정확성 검증, 단일 vs 배치 전송 성능 비교 테스트, 최대 배치 크기 한계 테스트, 실패 시나리오 (가스 부족, 잘못된 토큰 주소) 테스트",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "[BFS-2] Polygon Multicall3 컨트랙트 주소 설정",
            "description": "Polygon 네트워크의 Multicall3 컨트랙트 주소를 환경 설정에 추가하고 네트워크별 구성 관리",
            "jiraKey": "BFS-2",
            "dependencies": [],
            "details": "환경 변수에 Multicall3 컨트랙트 주소 (0xcA11bde05977b3631167028862bE2a173976CA11) 추가, 네트워크별 주소 매핑 구성, 환경 설정 검증 로직 구현\n<info added on 2025-07-21T13:56:54.550Z>\nPOLYGON_MULTICALL3_ADDRESS 환경 변수를 .env.sample에 추가 완료, config/index.ts에서 환경 변수 읽기와 주소 검증 로직이 구현됨, config/networks.ts 파일을 새로 생성하여 Amoy 테스트넷과 Polygon 메인넷 모두에 대해 Multicall3 주소 0xcA11bde05977b3631167028862bE2a173976CA11 매핑을 구성함\n</info added on 2025-07-21T13:56:54.550Z>\n<info added on 2025-07-21T14:20:16.702Z>\n기존 환경변수 기반 Multicall3 설정을 제거하고 중앙집중식 관리로 전환 완료. packages/shared/src/config/chains.config.json에 polygon, ethereum, bsc 체인 모두에 대해 multicall3Address 속성 추가됨. ChainProvider 클래스에 getMulticall3Address(chainType: ChainType) 메서드 구현하여 체인별 Multicall3 주소 조회 기능 제공. signing-service의 config/networks.ts와 환경변수 POLYGON_MULTICALL3_ADDRESS 설정 제거하여 중복 제거 및 일관된 설정 관리 달성.\n</info added on 2025-07-21T14:20:16.702Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "[BFS-3] MulticallService 클래스 구현",
            "description": "여러 ERC20 전송을 하나의 트랜잭션으로 배치 처리하는 MulticallService 핵심 클래스 개발",
            "jiraKey": "BFS-3",
            "dependencies": ["11.1"],
            "details": "MulticallService 클래스 구조 설계, 배치 전송 요청 처리 메서드, Multicall3 컨트랙트와의 인터페이스 구현, 에러 핸들링 로직 추가\n<info added on 2025-07-21T14:35:33.022Z>\nMulticallService 클래스 구현이 완료되었습니다. apps/signing-service/src/services/multicall.service.ts 파일에 다음 주요 메서드들이 구현되었습니다: prepareBatchTransfer (배치 전송 준비), encodeBatchTransaction (트랜잭션 인코딩), validateBatch (배치 검증), getOptimalBatchSize (최적 배치 크기 계산). ChainProvider를 통해 Multicall3 컨트랙트 주소를 동적으로 가져오도록 설계하였으며, apps/signing-service/src/services/__tests__/multicall.service.test.ts 테스트 파일을 작성하여 모든 기능에 대한 검증을 완료했습니다.\n</info added on 2025-07-21T14:35:33.022Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "[BFS-14] ABI 인코딩 및 calldata 생성 로직 구현",
            "description": "ERC20 전송을 위한 ABI 인코딩과 Multicall3용 calldata 생성 로직 개발",
            "jiraKey": "BFS-14",
            "dependencies": ["11.2"],
            "details": "ERC20 transfer 함수 ABI 인코딩, Multicall3 aggregate 함수를 위한 calldata 배열 생성, 인코딩 정확성 검증, 바이트 데이터 최적화",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "[BFS-15] 배치 크기 최적화 로직 구현",
            "description": "가스 한도 내에서 최대 전송 수를 계산하는 배치 크기 최적화 기능 개발",
            "jiraKey": "BFS-15",
            "dependencies": ["11.3"],
            "details": "가스 사용량 추정 로직, 블록 가스 한도 대비 최적 배치 크기 계산, 동적 배치 크기 조정 알고리즘, 가스비 효율성 분석",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "[BFS-16] TransactionSigner 확장 및 배치 서명 기능 추가",
            "description": "기존 TransactionSigner에 signBatchTransaction() 메서드를 추가하여 배치 트랜잭션 서명 지원",
            "jiraKey": "BFS-16",
            "dependencies": ["11.4"],
            "details": "signBatchTransaction() 메서드 구현, 단일 트랜잭션과 배치 트랜잭션 서명 로직 통합, nonce 관리 개선, 서명 검증 로직 추가",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "[BFS-17] 데이터 모델 업데이트 및 통합 테스트",
            "description": "WithdrawalRequest 모델에 type 필드 추가 및 전체 Multicall3 기능 통합 테스트 수행",
            "jiraKey": "BFS-17",
            "dependencies": ["11.5"],
            "details": "WithdrawalRequest 모델에 type: 'SINGLE' | 'BATCH' 필드 추가, 데이터베이스 스키마 업데이트, 단일/배치 전송 통합 테스트, 성능 비교 테스트 수행",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "[BFS-18] Multicall3 컨트랙트 주소 설정 및 ChainProvider 확장",
            "description": "Polygon 메인넷 및 테스트넷에 대한 Multicall3 컨트랙트 주소 설정 및 ChainProvider에서 주소 조회 기능 구현",
            "jiraKey": "BFS-18",
            "dependencies": [],
            "details": "Polygon 메인넷(0xcA11bde05977b3631167028862bE2a173976CA11) 및 Amoy 테스트넷 Multicall3 주소 추가, ChainProvider.getMulticallAddress() 메서드 구현, 네트워크별 주소 매핑 로직 추가, 환경 변수 기반 네트워크 선택 지원",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "[BFS-19] MulticallService 클래스 리팩토링 및 확장",
            "description": "기존 MulticallService를 확장하여 실제 배치 전송 기능 완성 및 성능 최적화",
            "jiraKey": "BFS-19",
            "dependencies": ["11.7"],
            "details": "MulticallService에서 실제 Multicall3 컨트랙트 호출 로직 구현, 배치 전송 결과 파싱 및 처리, 가스 추정 로직 개선, aggregate3 메서드를 사용한 배치 호출 구현, 실패한 전송 건 개별 처리 로직 추가",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "[BFS-20] ERC-20 ABI 인코딩 및 calldata 생성 로직 구현",
            "description": "ERC-20 transfer 메서드를 위한 ABI 인코딩 로직 및 Multicall3용 calldata 생성 기능 구현",
            "jiraKey": "BFS-20",
            "dependencies": ["11.8"],
            "details": "Ethers.js Interface를 사용한 transfer 메서드 인코딩, Multicall3.Call 구조체 생성 로직, 다중 토큰 전송을 위한 calldata 배열 생성, 각 전송 건별 target, allowFailure, callData 설정, ABI 인코딩 오류 핸들링",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 10,
            "title": "[BFS-21] 배치 크기 최적화 및 가스 계산 로직",
            "description": "가스 한도 내에서 최적의 배치 크기를 계산하고 동적으로 조정하는 기능 구현",
            "jiraKey": "BFS-21",
            "dependencies": ["11.9"],
            "details": "가스 한도 기반 최대 배치 크기 계산 알고리즘, 토큰별 전송 비용 추정, 배치 오버헤드 고려한 최적화, 동적 배치 분할 로직, Polygon 네트워크 가스 특성 반영, 배치 크기별 성능 테스트 및 벤치마킹\n<info added on 2025-07-22T15:13:46.918Z>\n구현 완료: Polygon 네트워크 기반 가스 최적화 시스템 - 30M 가스 한도와 75% 안전 마진을 적용한 동적 배치 분할 알고리즘 구현, 토큰별 가스 비용 학습 캐싱 시스템 도입으로 실시간 비용 예측 정확도 향상, 배치 크기에 따른 점감 가스 비용 계산 로직으로 배치 효율성 극대화, 향상된 fallback 가스 추정 메커니즘으로 네트워크 혼잡 상황 대응 강화, 모든 단위 테스트 및 통합 테스트 통과 확인\n</info added on 2025-07-22T15:13:46.918Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 11,
            "title": "[BFS-22] TransactionSigner 배치 전송 기능 확장",
            "description": "TransactionSigner 클래스에 배치 트랜잭션 서명 기능 추가 및 기존 단일 전송과의 통합",
            "jiraKey": "BFS-22",
            "dependencies": ["11.10"],
            "details": "signBatchTransaction() 메서드 구현, 배치 트랜잭션 가스 추정 로직, EIP-1559 트랜잭션 타입 지원, 배치와 단일 전송 구분 로직, nonce 관리 개선, 트랜잭션 서명 실패 시 개별 전송으로 fallback 메커니즘\n<info added on 2025-07-22T15:20:23.097Z>\nBFS-22 구현 완료. signBatchTransaction() 메서드와 signBatchTransactionWithSplitting() 메서드 추가하여 Multicall3 배치 전송 서명 지원. getGasPrice() 메서드 추출로 코드 중복 제거. 단일 및 분할 배치, 검증 실패 처리, 가스 추정, Redis 연결 에러 처리, 대용량 배치 시나리오 등에 대한 포괄적인 테스트 커버리지 구현. MulticallService와의 통합으로 배치 준비 및 인코딩 지원. Polygon 네트워크에서 EIP-1559 트랜잭션 지원. 배치 분할 시 순차적 nonce 관리 구현. 모든 테스트, 린트 검사, 타입 검사 통과 확인.\n</info added on 2025-07-22T15:20:23.097Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 12,
            "title": "[BFS-23] WithdrawalRequest 모델 업데이트 및 배치 처리 지원",
            "description": "WithdrawalRequest 모델에 배치 전송 타입 필드 추가 및 관련 데이터베이스 스키마 업데이트",
            "jiraKey": "BFS-23",
            "dependencies": ["11.11"],
            "details": "WithdrawalRequest에 type 필드 추가 ('SINGLE' | 'BATCH'), batchId 필드 추가로 배치 그룹 관리, Prisma 스키마 업데이트, 기존 레코드와의 호환성 보장, 배치 전송 상태 추적 로직, 배치 내 개별 전송 상태 관리 기능",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 13,
            "title": "[BFS-24] Multicall3 컨트랙트 주소 및 ABI 구성 설정",
            "description": "Polygon 네트워크용 Multicall3 컨트랙트 주소와 ABI 정의를 설정하고 네트워크별 구성 관리",
            "jiraKey": "BFS-24",
            "dependencies": [],
            "details": "Polygon 메인넷 및 테스트넷용 Multicall3 컨트랙트 주소 (0xcA11bde05977b3631167028862bE2a173976CA11) 설정, Multicall3 ABI 정의, 네트워크별 설정 파일 구성, 컨트랙트 주소 검증 로직",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 14,
            "title": "[BFS-25] MulticallService 클래스 기본 구조 구현",
            "description": "배치 전송을 위한 MulticallService 클래스의 기본 구조와 의존성 주입 설정",
            "jiraKey": "BFS-25",
            "dependencies": [],
            "details": "MulticallService 클래스 생성, Ethers.js Provider 및 Contract 인스턴스 초기화, 의존성 주입을 위한 생성자 설정, 기본 인터페이스 및 타입 정의, 에러 처리를 위한 기본 구조",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 15,
            "title": "[BFS-26] ERC20 transfer ABI 인코딩 로직 구현",
            "description": "ERC20 토큰 전송을 위한 ABI 인코딩과 calldata 생성 기능 개발",
            "jiraKey": "BFS-26",
            "dependencies": [],
            "details": "ERC20 transfer 함수 ABI 인코딩, 토큰 주소/수신자/금액 파라미터 검증, calldata 바이트 배열 생성, 인코딩 정확성 검증 로직, 인코딩 에러 핸들링",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 16,
            "title": "[BFS-27] 배치 크기 최적화 및 가스 계산 로직",
            "description": "가스 한도 내에서 최적의 배치 크기를 계산하고 가스비 추정 기능 구현",
            "jiraKey": "BFS-27",
            "dependencies": [],
            "details": "배치 전송당 가스 소모량 추정, 가스 한도 기반 최대 배치 크기 계산, 동적 배치 크기 조정 알고리즘, 가스비 최적화 로직, 배치 분할 전략 구현",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 17,
            "title": "[BFS-28] TransactionSigner에 배치 전송 메서드 확장",
            "description": "기존 TransactionSigner 클래스에 signBatchTransaction() 메서드 추가 및 통합",
            "jiraKey": "BFS-28",
            "dependencies": [],
            "details": "signBatchTransaction() 메서드 구현, Multicall3 트랜잭션 구조 생성, 기존 단일 전송과 배치 전송 로직 통합, 트랜잭션 타입별 분기 처리, 서명 검증 로직 확장\n<info added on 2025-07-22T08:36:49.185Z>\n실제 구현 완료: signBatchTransaction() 메서드가 TransactionSigner 클래스에 성공적으로 추가됨. BatchSigningRequest를 매개변수로 받아 여러 전송을 검증하고, MulticallService를 사용하여 배치를 준비한 후 단일 Multicall3 트랜잭션으로 서명하는 기능이 정상 동작함. SigningWorker에도 MulticallService 종속성 주입이 완료되었으며, 새로운 종속성을 포함하도록 모든 테스트가 수정됨.\n</info added on 2025-07-22T08:36:49.185Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 18,
            "title": "[BFS-29] WithdrawalRequest 모델 및 데이터베이스 스키마 업데이트",
            "description": "배치 전송 지원을 위한 모델 확장과 관련 데이터베이스 스키마 변경",
            "jiraKey": "BFS-29",
            "dependencies": [],
            "details": "WithdrawalRequest 모델에 type 필드 추가 ('SINGLE' | 'BATCH'), 배치 전송 관련 추가 필드 정의, Prisma 스키마 업데이트, 기존 데이터 호환성 보장, 마이그레이션 스크립트 작성\n<info added on 2025-07-22T13:41:16.651Z>\n새로운 구조: BatchTransaction 테이블을 생성하여 배치 메타데이터 저장 (batchId, totalAmount, tokenAddress, status, createdAt), WithdrawalRequest에 batchId 필드 추가하여 배치와 개별 요청 연결, SignedTransaction은 개별 트랜잭션 처리용으로 유지, 동적 배치 처리를 위한 관계형 구조 설계, 배치 상태 관리 및 추적 기능, 기존 단일 전송과의 하위 호환성 보장\n</info added on 2025-07-22T13:41:16.651Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 19,
            "title": "[BFS-30] SigningWorker 동적 배치 처리 로직 구현",
            "description": "큐 메시지를 분석하여 배치/단일 처리를 동적으로 결정하고 Multicall3 컨트랙트를 활용한 배치 처리 최적화 구현 [Updated: 2025. 7. 22.] [Updated: 2025. 7. 22.] [Updated: 2025. 7. 22.]",
            "jiraKey": "BFS-30",
            "status": "done",
            "dependencies": ["11.18"],
            "details": "SigningWorker 클래스의 processBatch() 메서드 리팩토링으로 동적 배치 처리 로직 구현:\n\n1. shouldUseBatchProcessing() 메서드 구현\n   - 환경 변수 ENABLE_BATCH_PROCESSING 체크 (기본값: true)\n   - 큐 메시지 수가 MIN_BATCH_SIZE (기본: 5) 이상인지 확인\n   - 동일 토큰 주소의 트랜잭션이 BATCH_THRESHOLD (기본: 3) 이상인지 검증\n   - 예상 가스 절약률이 MIN_GAS_SAVINGS_PERCENT (기본: 20%) 이상인지 계산\n\n2. groupByToken() 메서드 구현\n   ```typescript\n   private groupByToken(messages: Message<WithdrawalMessage>[]): Map<string, Message<WithdrawalMessage>[]> {\n     return messages.reduce((groups, message) => {\n       const tokenAddress = message.body.tokenAddress.toLowerCase();\n       if (!groups.has(tokenAddress)) {\n         groups.set(tokenAddress, []);\n       }\n       groups.get(tokenAddress)!.push(message);\n       return groups;\n     }, new Map());\n   }\n   ```\n\n3. calculateGasSavings() 메서드 구현\n   - 개별 처리 예상 가스: count * SINGLE_TX_GAS_ESTIMATE\n   - 배치 처리 예상 가스: BATCH_BASE_GAS + (count * BATCH_PER_TX_GAS)\n   - 절약률 계산: ((개별 - 배치) / 개별) * 100\n\n4. processBatch() 메서드 수정\n   ```typescript\n   async processBatch(messages: Message<WithdrawalMessage>[]): Promise<void> {\n     if (await this.shouldUseBatchProcessing(messages)) {\n       const tokenGroups = this.groupByToken(messages);\n       \n       for (const [tokenAddress, groupMessages] of tokenGroups) {\n         if (groupMessages.length >= this.config.BATCH_THRESHOLD) {\n           await this.processBatchGroup(tokenAddress, groupMessages);\n         } else {\n           await this.processSingleTransactions(groupMessages);\n         }\n       }\n     } else {\n       await this.processSingleTransactions(messages);\n     }\n   }\n   ```\n\n5. processBatchGroup() 메서드 구현\n   - BatchTransaction 엔티티 생성 (status: 'pending')\n   - 개별 Transaction 레코드 생성 및 batchId 연결\n   - Multicall3 컨트랙트 호출 데이터 생성\n   - 배치 트랜잭션 서명 및 전송\n   - 결과에 따른 상태 업데이트\n\n6. 환경 변수 설정\n   ```env\n   ENABLE_BATCH_PROCESSING=true\n   MIN_BATCH_SIZE=5\n   BATCH_THRESHOLD=3\n   MIN_GAS_SAVINGS_PERCENT=20\n   SINGLE_TX_GAS_ESTIMATE=65000\n   BATCH_BASE_GAS=100000\n   BATCH_PER_TX_GAS=25000\n   ```\n\n7. 로깅 및 메트릭 추가\n   - 배치 처리 결정 로직 로깅\n   - 가스 절약 예상치 로깅\n   - 배치 처리 성공/실패 메트릭\n<info added on 2025-07-22T14:01:02.619Z>\n종속성 업데이트: 이전 종속성인 11, 11.3, 11.4에서 11.18 (WithdrawalRequest 모델 및 데이터베이스 스키마 업데이트)로 변경. 11.11, 11.11.3, 11.11.4는 존재하지 않는 태스크였으므로 제거됨.\n</info added on 2025-07-22T14:01:02.619Z>\n<info added on 2025-07-22T14:09:36.960Z>\nJira 이슈 키: BFS-30\n</info added on 2025-07-22T14:09:36.960Z>\n<info added on 2025-07-22T14:13:27.897Z>\n제목을 \"[BFS-30] SigningWorker 동적 배치 처리 로직 구현\"으로 업데이트함. Jira 이슈 키 BFS-30이 제목에 접두사로 추가됨.\n</info added on 2025-07-22T14:13:27.897Z>\n<info added on 2025-07-23T02:11:54.817Z>\n코드베이스 분석 결과:\n- SigningWorker가 BaseWorker를 상속받아 processBatch() 메서드 사용\n- 현재는 개별 트랜잭션 처리만 구현되어 있음\n- MulticallService가 이미 구현되어 배치 처리 기능 제공\n- BatchTransaction 모델이 Prisma 스키마에 정의됨\n- Config 클래스를 통한 환경 변수 관리 구조 확인\n\n구현 준비사항:\n- BaseWorker의 기존 processBatch() 메서드를 오버라이드하여 동적 배치 처리 로직 추가\n- MulticallService와의 연동을 통한 실제 배치 트랜잭션 실행\n- Config 클래스에 배치 처리 관련 환경 변수 추가 필요\n- BatchTransaction 모델을 활용한 배치 상태 관리 구현\n</info added on 2025-07-23T02:11:54.817Z>\n<info added on 2025-07-23T02:19:48.749Z>\n구현 완료 - 2025년 7월 23일:\n\n✅ 주요 구현 사항:\n- shouldUseBatchProcessing(): 환경변수(ENABLE_BATCH_PROCESSING), 메시지 수(MIN_BATCH_SIZE), 토큰 그룹 크기(BATCH_THRESHOLD), 가스 절약률(MIN_GAS_SAVINGS_PERCENT) 기반 동적 판단 로직 완성\n- groupByToken(): 토큰 주소별 메시지 그룹화 메서드 구현\n- calculateGasSavings(): 배치 vs 개별 처리 가스 비용 비교 및 절약률 계산 로직 구현\n- processBatch() 메서드 오버라이드: BaseWorker 상속하여 배치/개별 처리 분기 로직 완성\n- processBatchTransactions(): 토큰 그룹별 배치 처리 실행 메서드 구현\n- processBatchGroup(): BatchTransaction 엔티티 생성, Multicall3 컨트랙트 연동, 트랜잭션 서명 및 상태 관리 완성\n\n✅ 검증 완료:\n- 모든 단위 테스트 작성 및 통과\n- TypeScript 타입체크 통과\n- ESLint 코드 품질 검사 통과\n- MulticallService와의 연동 검증 완료\n\n구현된 기능으로 동적 배치 처리 최적화를 통한 가스 비용 절약 및 트랜잭션 처리 효율성 향상 달성.\n</info added on 2025-07-23T02:19:48.749Z>",
            "testStrategy": "1. shouldUseBatchProcessing() 단위 테스트\n   - 환경 변수가 false일 때 항상 false 반환 확인\n   - 메시지 수가 MIN_BATCH_SIZE 미만일 때 false 반환 확인\n   - 동일 토큰 그룹이 BATCH_THRESHOLD 미만일 때 false 반환 확인\n   - 가스 절약률이 MIN_GAS_SAVINGS_PERCENT 미만일 때 false 반환 확인\n   - 모든 조건 충족 시 true 반환 확인\n\n2. groupByToken() 단위 테스트\n   - 빈 메시지 배열 처리 확인\n   - 단일 토큰 주소 그룹핑 확인\n   - 여러 토큰 주소 정확한 그룹핑 확인\n   - 대소문자 정규화 확인 (0xABC와 0xabc가 같은 그룹)\n\n3. calculateGasSavings() 단위 테스트\n   - 다양한 트랜잭션 수에 대한 절약률 계산 정확성\n   - 음수 절약률 처리 (배치가 더 비쌀 때)\n   - 경계값 테스트 (1개, 2개, 임계값 근처)\n\n4. processBatch() 통합 테스트\n   - 배치 처리 비활성화 시 모든 트랜잭션 개별 처리 확인\n   - 메시지 수 부족 시 개별 처리 확인\n   - 동일 토큰 그룹이 임계값 이상일 때만 배치 처리 확인\n   - 혼합 시나리오 테스트 (일부는 배치, 일부는 개별)\n\n5. processBatchGroup() 통합 테스트\n   - BatchTransaction 레코드 생성 확인\n   - 개별 Transaction 레코드의 batchId 연결 확인\n   - Multicall3 호출 데이터 정확성 검증\n   - 성공/실패 시 상태 업데이트 확인\n\n6. E2E 테스트\n   - 실제 큐 메시지로 전체 플로우 테스트\n   - 배치 처리 후 블록체인 상태 검증\n   - 가스 사용량 실제 측정 및 예상치 비교"
          }
        ]
      },
      {
        "id": 12,
        "title": "[BFS-5] tx-broadcaster 서비스 구현",
        "description": "서명된 트랜잭션을 Polygon 네트워크에 브로드캐스트하는 서비스 개발",
        "jiraKey": "BFS-5",
        "details": "Nx를 사용하여 tx-broadcaster 앱 생성 (nx g @nx/node:app tx-broadcaster), signed-tx-queue에서 SQS 메시지 폴링, 데이터베이스에서 서명된 트랜잭션 조회, Ethers.js v6를 사용하여 Polygon 네트워크 브로드캐스트, 트랜잭션 상태를 SIGNED → BROADCASTED → CONFIRMED로 업데이트, nonce 충돌 감지 및 DLQ 처리, RPC 실패 시 지수 백오프 재시도 로직, 브로드캐스트 성공 후 tx-monitor-queue에 메시지 전송",
        "testStrategy": "정상 브로드캐스트 플로우 테스트, nonce 충돌 시나리오 테스트, RPC 실패 및 재시도 테스트, 재시도 한도 초과 시 DLQ 처리 테스트, 단일/배치 트랜잭션 브로드캐스트 테스트",
        "priority": "high",
        "dependencies": [11],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "[BFS-6] tx-monitor 서비스 구현",
        "description": "브로드캐스트된 트랜잭션의 상태를 추적하고 확인하는 모니터링 서비스 개발",
        "jiraKey": "BFS-6",
        "details": "Nx를 사용하여 tx-monitor 앱 생성, tx-monitor-queue에서 브로드캐스트된 트랜잭션 수신, Polygon 네트워크에서 트랜잭션 상태 및 confirmations 수 추적, 12 confirmations 달성 시 CONFIRMED 상태로 업데이트, 실패한 트랜잭션 감지 및 알림, 장기간 pending 상태인 트랜잭션에 대한 가스비 인상 재시도 트리거, Redis를 사용한 모니터링 상태 캐싱으로 성능 최적화, 배치 트랜잭션의 경우 모든 개별 전송 확인",
        "testStrategy": "트랜잭션 확인 수 추적 테스트, 성공/실패 트랜잭션 상태 업데이트 테스트, 장기간 pending 트랜잭션 감지 테스트, 가스비 인상 재시도 로직 테스트, 배치 트랜잭션 모니터링 테스트",
        "priority": "high",
        "dependencies": [12],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "[BFS-7] DLQ(Dead Letter Queue) 핸들러 구현",
        "description": "실패한 메시지 처리 및 복구를 위한 DLQ 핸들러 서비스 개발",
        "jiraKey": "BFS-7",
        "details": "각 큐(tx-request-queue, signed-tx-queue)에 대한 DLQ 설정, 실패 메시지 분류 로직 (영구적 실패 vs 일시적 실패), 재시도 자격 판단 알고리즘 (시간 기반, 실패 유형 기반), 재시도 가능한 메시지를 원본 큐로 재전송, 수동 개입이 필요한 메시지에 대한 알림 시스템, DLQ 메시지 조회 및 관리 API, 실패 패턴 분석 및 로깅",
        "testStrategy": "영구적 vs 일시적 실패 분류 테스트, 재시도 로직 검증 테스트, DLQ 메시지 복구 테스트, 수동 개입 알림 테스트, 실패 패턴 분석 테스트",
        "priority": "medium",
        "dependencies": [12],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "[BFS-8] signing-service 잔액 검증 기능 구현",
        "description": "트랜잭션 서명 전 실제 토큰 잔액 및 가스 수수료 검증 기능 추가",
        "jiraKey": "BFS-8",
        "details": "ERC-20 토큰 잔액 확인을 위한 BalanceService 구현, Ethers.js를 사용하여 토큰 컨트랙트 잔액 조회, 네이티브 토큰(MATIC) 잔액 확인, 가스 수수료 계산 및 검증 (EIP-1559 기준), 출금 한도 확인 로직, Redis를 활용한 잔액 정보 캐싱 (30초 TTL), 배치 전송의 경우 총 출금 금액과 잔액 비교, 잔액 부족 시 적절한 에러 응답",
        "testStrategy": "토큰 잔액 조회 정확성 테스트, 가스 수수료 계산 테스트, 잔액 부족 시나리오 테스트, 캐싱 동작 검증 테스트, 배치 전송 잔액 검증 테스트",
        "priority": "medium",
        "dependencies": [11],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "[BFS-9] Admin API 인증 시스템 구현",
        "description": "JWT 기반 인증 및 역할 기반 접근 제어를 포함한 Admin API 시스템 구축",
        "jiraKey": "BFS-9",
        "details": "User 모델 및 Prisma 스키마 추가, bcrypt를 사용한 패스워드 해싱, JWT 토큰 생성/검증 미들웨어, 역할 기반 접근 제어 (USER, ADMIN, SUPER_ADMIN), 인증 엔드포인트 구현 (POST /auth/register, POST /auth/login, POST /auth/refresh), API Rate Limiting (IP 기반: 60/분, 사용자 기반: 100/분), 토큰 갱신 로직, 세션 관리 및 보안 헤더 설정",
        "testStrategy": "사용자 등록/로그인 플로우 테스트, JWT 토큰 검증 테스트, 역할 기반 접근 제어 테스트, Rate Limiting 동작 테스트, 토큰 갱신 로직 테스트",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "[BFS-10] Admin API 관리 기능 구현",
        "description": "트랜잭션, 큐, 사용자 관리를 위한 Admin API 엔드포인트 구현",
        "jiraKey": "BFS-10",
        "details": "트랜잭션 관리 API (GET /admin/transactions, GET /admin/transactions/:id, POST /admin/transactions/:id/retry, PUT /admin/transactions/:id/status), 큐 관리 API (GET /admin/queues, GET /admin/queues/:name/messages, POST /admin/queues/:name/purge), 사용자 관리 API (GET /admin/users, POST /admin/users, PUT /admin/users/:id, DELETE /admin/users/:id), 시스템 통계 및 분석 API (GET /admin/stats, GET /admin/analytics, GET /admin/health), 검색/필터링/페이징 기능, 감사 로그 기록",
        "testStrategy": "각 Admin API 엔드포인트 기능 테스트, 권한 검증 테스트, 검색/필터링 정확성 테스트, 페이징 동작 테스트, 감사 로그 기록 테스트",
        "priority": "medium",
        "dependencies": [16],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "[BFS-11] Admin UI React 애플리케이션 구현",
        "description": "관리자를 위한 React 기반 웹 인터페이스 구현",
        "jiraKey": "BFS-11",
        "details": "Nx를 사용하여 React 앱 생성 (nx add @nx/react, nx g @nx/react:app admin-ui), Ant Design + Tailwind CSS를 활용한 UI 컴포넌트, TanStack Query(서버 상태) + Zustand(클라이언트 상태) 상태 관리, 실시간 대시보드 (트랜잭션 통계, 시스템 상태), 트랜잭션 관리 페이지 (검색/필터, 상태 추적, 수동 재시도), 큐 모니터링 페이지, 사용자 관리 페이지, Recharts를 사용한 데이터 시각화, 반응형 디자인 구현",
        "testStrategy": "각 페이지 렌더링 테스트, 사용자 상호작용 테스트, 실시간 데이터 업데이트 테스트, 반응형 디자인 테스트, 접근성(a11y) 테스트",
        "priority": "medium",
        "dependencies": [17],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "[BFS-12] WebSocket 실시간 통신 시스템 구현",
        "description": "Admin UI와 백엔드 간 실시간 데이터 업데이트를 위한 WebSocket 통신 구현",
        "jiraKey": "BFS-12",
        "details": "Socket.IO를 사용한 WebSocket 서버 구현, 클라이언트-서버 이벤트 정의 (queue:update, transaction:update, system:alert), 구독/구독 취소 메커니즘, 실시간 큐 상태 모니터링, 트랜잭션 상태 변경 실시간 알림, 시스템 알림 브로드캐스트, 연결 상태 관리 및 재연결 로직, JWT 토큰 기반 WebSocket 인증",
        "testStrategy": "WebSocket 연결/해제 테스트, 실시간 이벤트 전송/수신 테스트, 구독/구독 취소 테스트, 재연결 로직 테스트, 인증된 WebSocket 연결 테스트",
        "priority": "low",
        "dependencies": [18],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "[BFS-13] Prometheus 메트릭 및 모니터링 시스템 구현",
        "description": "시스템 모니터링 및 알림을 위한 Prometheus 메트릭 수집 및 Grafana 대시보드 구축",
        "jiraKey": "BFS-13",
        "details": "prom-client를 사용한 Prometheus 메트릭 수집, 애플리케이션 메트릭 정의 (api_request_duration_seconds, queue_message_count, transaction_total), 시스템 메트릭 수집 (CPU, 메모리, 디스크 사용률), Grafana 대시보드 구성, 알림 임계값 설정 (API 오류율 > 5%, 큐 메시지 > 1000개), AlertManager 연동, 이메일/Slack 알림 설정, 메트릭 보존 정책 설정",
        "testStrategy": "메트릭 수집 정확성 테스트, 알림 트리거 테스트, Grafana 대시보드 시각화 테스트, 임계값 기반 알림 테스트, 메트릭 데이터 보존 테스트",
        "priority": "low",
        "dependencies": [13],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "[BFS-31] 영구 연결을 위한 자동 재연결 로직 구현",
        "description": "Redis, 블록체인 노드 등의 영구 연결이 끊어졌을 때 자동으로 재연결을 시도하는 복원력 있는 연결 관리 시스템을 구현합니다.",
        "status": "pending",
        "dependencies": [15, 20],
        "priority": "medium",
        "details": "연결 관리를 위한 ConnectionManager 클래스 구현 (재연결 로직, 연결 상태 추적, 이벤트 발생), Redis 재연결 로직 구현 (ioredis의 reconnectOnError 활용, 지수 백오프 재시도 전략, 최대 재시도 횟수 제한), 블록체인 노드 재연결 구현 (Ethers.js의 WebSocketProvider 재연결 처리, 폴백 RPC 엔드포인트 설정, 연결 상태 모니터링), 재연결 전략 설정 (초기 재시도 간격: 1초, 최대 재시도 간격: 30초, 지수 백오프 계수: 2, 최대 재시도 횟수: 10회), 연결 상태 이벤트 (connected, disconnected, reconnecting, reconnected, error), 헬스체크 엔드포인트에 연결 상태 포함, 연결 실패 시 graceful degradation 처리, 연결 복구 시 대기 중인 작업 재개 로직, 연결 상태 메트릭 수집 (Prometheus)",
        "testStrategy": "Redis 연결 끊김 및 자동 재연결 테스트, 블록체인 노드 연결 실패 시나리오 테스트, 지수 백오프 재시도 간격 검증, 최대 재시도 횟수 도달 시 동작 테스트, 동시 다중 연결 재연결 테스트, 연결 복구 후 대기 작업 처리 테스트, 헬스체크 연결 상태 반영 테스트, 메트릭 수집 정확성 테스트",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "[BFS-32] Implement Hardhat node-based localhost chain support",
        "description": "Implement localhost blockchain network support based on Hardhat node for local development and testing environment. This enables fast and reliable development environment without external testnet dependencies. Ready to proceed sequentially starting from the first subtask.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "Hardhat development environment setup (npm install --save-dev hardhat @nomicfoundation/hardhat-ethers ethers, npx hardhat init for basic project structure, hardhat.config.ts configuration file setup), Local network configuration (defaultNetwork: 'hardhat', networks.hardhat settings - chainId: 31337, mining.auto: true, mining.interval: 3000ms, accounts configuration - including LocalStack private key 0x0000000000000000000000000000000000000000000000000000000000000001), Localhost chain configuration in chains.config.json (chainId: 31337, name: 'localhost', rpcUrl: 'http://127.0.0.1:8545' configuration, explicit chain parameter specification in API requests), NetworkConfig type extension (localhost network configuration addition, chainId: 31337, name: 'localhost', rpcUrl setting through ChainProvider mechanism), Smart contract deployment scripts (scripts/deploy-localhost.ts implementation, ERC20 token contract deployment, Multicall3 contract deployment, transfer all test tokens to signing address, export deployed addresses as environment variables), Local development workflow improvement (integrate hardhat service into existing docker-compose, run npx hardhat node --hostname 0.0.0.0, automatic account creation and funding, block mining interval configuration), Test helper utility implementation (test account creation functions, test token transfer functions, block timestamp manipulation functions, snapshot/revert functionality), Developer tools integration (utilize Hardhat Network Helper, console.log debugging support, gas reporting configuration, solidity coverage measurement), Fork mode support (polygon mainnet/testnet fork functionality, fork from specific block height, simulate real network state), Automation scripts (add npm run dev:localhost command, sequential execution: start Hardhat node → deploy contracts → setup test data → start API server). Now ready to start from the first subtask (22.1).",
        "testStrategy": "Hardhat node connection test (localhost RPC connection verification, chain ID 31337 validation), Test account operation verification (confirm signing address 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf created with LocalStack private key, verify ETH and token balances of signing address), ERC20 token deployment and transfer test (confirm successful token contract deployment, verify all tokens transferred to signing address, test token transfer transactions, validate balance query accuracy), Multicall3 contract test (verify batch call functionality, test multi-token balance queries), Block mining operation test (verify automatic mining interval, test manual mining trigger), Transaction processing flow test (complete flow: withdrawal request → queue → processing → monitoring, gas estimation on local network, transaction receipt queries), Fork mode test (mainnet fork state verification, test interactions with real contracts), Development environment integration test (execute full stack with docker-compose up, verify automatic deployment script operation, API server and local blockchain integration), ChainProvider localhost configuration test (verify localhost chain handling through existing provider mechanism, test explicit chain parameter specification in API requests), Performance comparison test (compare local vs testnet transaction speeds, measure development workflow efficiency)",
        "subtasks": [
          {
            "id": 1,
            "title": "Hardhat development environment setup and project initialization",
            "description": "Install Hardhat packages and configure basic project structure with TypeScript-based configuration files. [Updated: 2025. 7. 23.] [Updated: 2025. 7. 23.]",
            "status": "done",
            "dependencies": [],
            "details": "Execute npm install --save-dev hardhat @nomicfoundation/hardhat-ethers ethers @typechain/hardhat typechain @typechain/ethers-v6, create TypeScript project with npx hardhat init, generate hardhat.config.ts file with basic configuration, setup contracts/, scripts/, test/ directory structure, add artifacts/, cache/, typechain-types/ to .gitignore, add Hardhat type references to tsconfig.json\n<info added on 2025-07-23T13:07:54.480Z>\ndocker/hardhat directory structure creation: create docker/hardhat/ folder with package.json (including hardhat, @nomicfoundation/hardhat-ethers, ethers, @typechain/hardhat, typechain dependencies), hardhat.config.js (network settings - localhost:8545, chainId:31337, account configuration), Dockerfile and docker-compose.yml service definition for running Hardhat node in Docker environment, setup to run local blockchain network with hardhat node command inside container\n</info added on 2025-07-23T13:07:54.480Z>\n<info added on 2025-07-23T13:16:15.109Z>\nJira key mapping added to BFS-33 - indicates this subtask is linked to Jira issue BFS-33\n</info added on 2025-07-23T13:16:15.109Z>\n<start-ready on 2025-07-23T13:30:00.000Z>\nReady to start immediately: Begin with the first subtask of installing Hardhat packages and initial setup. Includes docker/hardhat directory structure creation and Hardhat node execution environment setup.\n</start-ready on 2025-07-23T13:30:00.000Z>\n<info added on 2025-07-23T14:46:20.347Z>\n작업 제목과 설명 영어 번역 완료:\n\nTitle: \"Hardhat development environment setup and project initialization\"\nDescription: \"Install Hardhat packages and configure basic project structure with TypeScript-based configuration files.\"\n\n영어 번역본이 이미 기존 작업 내용에 반영되어 있으며, 해당 작업은 Hardhat 개발 환경 설정 및 프로젝트 초기화를 수행하는 첫 번째 서브태스크입니다.\n</info added on 2025-07-23T14:46:20.347Z>",
            "testStrategy": "Verify Hardhat installation (npx hardhat --version), validate project structure, confirm successful TypeScript compilation, test hardhat compile command execution, test Hardhat node execution in Docker environment"
          },
          {
            "id": 2,
            "title": "Localhost chain configuration in chains.config.json and ChainProvider integration",
            "description": "Configure localhost chain in chains.config.json and integrate with existing ChainProvider mechanism, removing environment variable dependencies.",
            "status": "done",
            "dependencies": [1],
            "details": "Add localhost chain configuration to chains.config.json (chainId: 31337, name: 'localhost', symbol: 'ETH', decimals: 18, rpcUrl: 'http://127.0.0.1:8545'), add 'localhost' to ChainName type in packages/shared/src/types/chain.types.ts, add localhost case handling in packages/shared/src/providers/chain-provider.factory.ts (create JsonRpcProvider instance), add networks.hardhat configuration to hardhat.config.ts (chainId: 31337, mining.auto: true, mining.interval: 3000, accounts configuration - including LocalStack private key 0x0000000000000000000000000000000000000000000000000000000000000001 to generate signing address 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf), integrate hardhat service into existing docker-compose.yaml (run npx hardhat node --hostname 0.0.0.0), remove environment variable setup for POLYGON_NETWORK=localhost, LOCALHOST_RPC_URL, LOCALHOST_SIGNING_PRIVATE_KEY\n<info added on 2025-07-24T07:36:28.619Z>\n구현 완료: localhost 체인 설정이 성공적으로 완료됨. chains.config.json에 chainId 31337로 localhost 체인 추가, ChainName 및 ChainNetwork 타입에 localhost 포함 업데이트, ChainProviderFactory에 createLocalhostProvider 메서드 추가, hardhat.config.ts에 3초 마이닝 간격과 LocalStack 개인키 설정 적용, docker-compose.yaml에 hardhat-node 및 hardhat-deploy 서비스 추가, signing-service에서 Polygon 관련 환경변수 제거. 모든 TypeScript 타입 검사 및 린트 검사 통과 확인.\n</info added on 2025-07-24T07:36:28.619Z>",
            "testStrategy": "Validate localhost chain configuration loading from chains.config.json, test ChainProvider.getProvider('localhost') functionality, verify hardhat node connection through provider, test signing address generation from LocalStack private key, validate docker-compose hardhat service integration, confirm removal of environment variable dependencies"
          },
          {
            "id": 3,
            "title": "ERC20 token and Multicall3 contract deployment script implementation",
            "description": "Implement scripts to deploy test ERC20 tokens and Multicall3 contract, transferring all tokens to the signing address.",
            "status": "done",
            "dependencies": [2],
            "details": "Create contracts/TestToken.sol (inherit OpenZeppelin ERC20, include minting function), add contracts/Multicall3.sol (for batch calls), write scripts/deploy-localhost.ts deployment script, deploy ERC20 token and transfer all tokens (e.g., 1,000,000 TEST) to signing address 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf, deploy Multicall3 contract, save deployed contract addresses to .env.localhost file (TEST_TOKEN_ADDRESS, MULTICALL3_ADDRESS), create scripts/setup-test-data.ts for test data setup (user creation, sample withdrawal requests, etc.), automate type generation with TypeChain\n<info added on 2025-07-23T13:08:36.235Z>\nCreate contracts/Multicall3.sol file using provided Multicall3.sol code, create contracts/TestToken.sol file (inherit OpenZeppelin ERC20 with minting functionality), write scripts/deploy.js deployment script (deploy both contracts and transfer all tokens to signing address 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf), save deployment information to deployment.json file (instead of or in addition to existing .env.localhost)\n</info added on 2025-07-23T13:08:36.235Z>\n<info added on 2025-07-25T01:54:27.287Z>\n구현 완료: contracts/TestToken.sol (OpenZeppelin ERC20 상속 및 minting 기능), contracts/Multicall3.sol (전체 구현), scripts/deploy.js 배포 스크립트 (두 컨트랙트 배포 및 signing address 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf로 모든 토큰 전송), hardhat.config.js 컴파일 설정. 배포 스크립트는 컨트랙트 주소를 deployment.json과 .env.localhost 파일 양쪽에 저장. 컨트랙트 컴파일 성공 확인.\n</info added on 2025-07-25T01:54:27.287Z>",
            "testStrategy": "Verify successful contract compilation, test deployment script execution, confirm all tokens transferred to signing address, test Multicall3 batch call functionality, verify contract addresses saved to environment variables"
          },
          {
            "id": 4,
            "title": "Test helper utilities and developer tools implementation",
            "description": "Implement helper functions for efficient testing on Hardhat network and integrate developer tools.",
            "status": "done",
            "dependencies": [3],
            "details": "Create packages/shared/src/utils/hardhat-helpers.ts (getSigningAccount, fundAccount, advanceTime, takeSnapshot/revertToSnapshot functions, Multicall3 interface functions), integrate Hardhat Network Helpers (@nomicfoundation/hardhat-network-helpers), setup console.log debugging support, configure hardhat-gas-reporter plugin, setup solidity-coverage plugin, add Fork mode support (forking configuration in hardhat.config.ts), add signing address related helper functions\n<info added on 2025-07-23T13:08:56.753Z>\nImplement init-hardhat.sh script: Hardhat node waiting logic (check http://127.0.0.1:8545 status with curl, wait up to 30 seconds), contract compilation (execute npx hardhat compile), deployment script execution (node scripts/deploy.js), integration with hardhat-deploy service in docker-compose.yaml (set depends_on to run after hardhat-node is ready, dependency management through healthcheck), script execution permissions (chmod +x init-hardhat.sh), error handling and logging (output success/failure logs for each step)\n</info added on 2025-07-23T13:08:56.753Z>",
            "testStrategy": "Unit test helper functions, test signing address query functions, verify snapshot/revert functionality operation, validate time manipulation function accuracy, confirm gas reporting output, test Multicall3 helper functions"
          },
          {
            "id": 5,
            "title": "Automation scripts and development workflow integration with explicit chain parameter support",
            "description": "Create automation scripts for local development environment and integrate with existing Docker Compose system using explicit chain parameters instead of environment variables.",
            "status": "done",
            "dependencies": [4],
            "details": "Add dev:localhost script to package.json (sequential execution: start Hardhat node → deploy contracts → setup test data → start API server), write scripts/start-local-dev.sh shell script, modify all microservices to recognize localhost chain through explicit chain parameter specification in API requests (not environment variables), update blockchain connection logic in withdrawal-api, tx-processor, tx-monitor services to use ChainProvider with explicit chain='localhost' parameter, fully integrate hardhat service into existing docker-compose.yaml file, add dependency management with LocalStack, update README.md with local development guide (including LocalStack private key, signing address, Multicall3 usage, explicit chain parameter usage), add hardhat-node and hardhat-deploy service configuration to docker-compose.yaml file (hardhat-node: use hardhat/hardhat:latest image, port mapping 8545:8545, chain-id 31337 setting; hardhat-deploy: dedicated service for contract deployment, hardhat-node dependency setting), update all microservices (withdrawal-api, tx-processor, tx-monitor) to handle localhost chain through ChainProvider mechanism, set Multicall3 contract address for localhost chain (0xcA11bde05977b3631167028862bE2a173976CA11 standard address or deployed address), manage inter-service network dependencies (sequential start: hardhat-node → hardhat-deploy → api services), healthcheck configuration to verify service readiness",
            "testStrategy": "Test complete local development environment startup, verify Docker Compose integration, validate inter-service communication with explicit chain parameters, test complete flow using signing address: withdrawal request → processing → monitoring, test batch queries using Multicall3, test automatic restart and state recovery, verify API requests properly specify chain parameter, test ChainProvider localhost chain handling"
          },
          {
            "id": 6,
            "title": "[BFS-39] 로컬 체인 수동 통합 테스트 및 검증",
            "description": "Docker 환경에서 Hardhat 노드의 정상 작동을 확인하고, 배포된 토큰 및 Multicall3 컨트랙트를 검증하며, API를 통한 실제 출금 요청부터 트랜잭션 처리까지 전체 플로우를 엔드투엔드로 테스트합니다. [Updated: 2025. 7. 27.]",
            "status": "done",
            "dependencies": [],
            "details": "**Docker 환경 Hardhat 노드 검증**\n- docker-compose로 Hardhat 노드 컨테이너 실행 확인\n- localhost:8545 RPC 연결 및 chain ID 31337 검증\n- 사전 설정된 계정 잔액 및 시드 데이터 확인\n\n**컨트랙트 배포 및 검증**\n- MOCK ERC20 토큰 컨트랙트 배포 확인 (이름, 심볼, decimals 검증)\n- Multicall3 컨트랙트 배포 확인 (주소: 0xcA11bde05977b3631167028862bE2a173976CA11)\n- 각 컨트랙트의 함수 호출 가능 여부 테스트\n- 초기 토큰 민팅 및 배분 확인\n\n**API 엔드투엔드 테스트**\n- withdrawal-api에 실제 출금 요청 POST /withdrawal\n- 단일 토큰 출금 요청 처리 확인\n- 배치 출금 요청 처리 확인 (Multicall3 사용)\n- 잘못된 주소/토큰으로 실패 케이스 테스트\n\n**트랜잭션 처리 플로우 검증**\n- SQS 큐를 통한 메시지 전달 확인\n- tx-processor의 트랜잭션 서명 및 브로드캐스트\n- tx-monitor의 트랜잭션 상태 추적\n- 데이터베이스에 올바른 상태 업데이트 확인\n\n**가스 추정 및 배치 처리 테스트**\n- 단일 토큰 전송의 가스 추정 정확성 검증\n- Multicall3 배치 전송의 가스 효율성 측정\n- 최대 배치 크기 테스트 (가스 한도 내 최대 전송 수)\n- 가스 가격 변동 시나리오 테스트\n<info added on 2025-07-26T16:34:33.627Z>\n**제목 변경 완료**\n- 기존 제목: \"로컬 체인 수동 통합 테스트 및 검증\"\n- 새 제목: \"[BFS-39] 로컬 체인 수동 통합 테스트 및 검증\"\n\n**Jira 동기화 상태**\n- Task Master 제목에 Jira 키 [BFS-39] 추가됨\n- 부모 Task 22와 동일한 Jira 키 사용 (서브태스크는 별도 Jira 이슈 없음)\n- 제목 업데이트로 Jira 연동 일관성 확보 완료\n</info added on 2025-07-26T16:34:33.627Z>",
            "testStrategy": "**1. 환경 준비 테스트**\n- Docker 컨테이너 정상 실행 확인 (hardhat-node, mysql, localstack)\n- 모든 서비스 간 네트워크 연결 확인\n- 환경 변수 설정 검증\n\n**2. 컨트랙트 검증 테스트**\n- ethers.js로 MOCK 토큰 컨트랙트 연결 및 기본 정보 조회\n- Multicall3 컨트랙트 연결 및 aggregate 함수 호출 테스트\n- 테스트 계정의 토큰 잔액 확인\n\n**3. API 기능 테스트**\n- Postman/curl로 단일 출금 요청 (200 OK 응답 확인)\n- 배치 출금 요청 (여러 수신자, 동일 토큰)\n- 잘못된 요청 (400/422 에러 응답 확인)\n- 인증되지 않은 요청 (401 에러 확인)\n\n**4. 전체 플로우 통합 테스트**\n- API 요청 → SQS 메시지 → 트랜잭션 서명 → 블록체인 전송 → 상태 업데이트\n- 각 단계별 로그 및 데이터베이스 상태 확인\n- 트랜잭션 해시 및 receipt 검증\n\n**5. 성능 및 한계 테스트**\n- 단일 vs 배치 전송 가스 비용 비교\n- 최대 배치 크기에서의 트랜잭션 성공 여부\n- 동시 다중 요청 처리 능력 테스트\n- 네트워크 지연 시뮬레이션 테스트"
          }
        ]
      },
      {
        "id": 23,
        "title": "[BFS-38] 네이티브 토큰(ETH, MATIC, BNB 등) 출금 지원 구현",
        "description": "현재 ERC-20 토큰만 지원하는 시스템을 확장하여 네이티브 토큰(ETH, MATIC, BNB 등)의 출금을 지원하도록 구현합니다. API 레벨에서의 검증부터 signing-service의 트랜잭션 처리까지 전체 파이프라인을 수정합니다.",
        "status": "pending",
        "dependencies": [11, 15, 22],
        "priority": "medium",
        "details": "**Jira 키: BFS-38**\n\n1. **토큰 타입 구분 체계 구현**\n   - WithdrawalRequest 모델에 tokenType 필드 추가 ('NATIVE' | 'ERC20')\n   - 토큰 주소가 '0x0' 또는 null인 경우 네이티브 토큰으로 식별\n   - packages/shared/src/types에 TokenType enum 정의\n\n2. **API 레벨 변경사항**\n   - withdrawal-api의 validator에서 네이티브 토큰 요청 허용\n   - 네이티브 토큰의 경우 tokenAddress를 '0x0000000000000000000000000000000000000000' 또는 null로 처리\n   - 요청 검증 시 네이티브 토큰과 ERC20 토큰 별도 처리 로직 추가\n\n3. **signing-service 수정사항**\n   - TransactionSigner 클래스에 네이티브 토큰 전송 로직 추가\n   - 네이티브 토큰은 배치 처리(Multicall3) 불가능하도록 제한\n   - signNativeTransaction() 메서드 구현:\n     ```typescript\n     async signNativeTransaction(request: WithdrawalRequest): Promise<TransactionResponse> {\n       const tx = {\n         to: request.recipientAddress,\n         value: ethers.parseUnits(request.amount, 18), // 네이티브 토큰은 항상 18 decimals\n         gasLimit: 21000, // 네이티브 전송은 고정 가스\n         maxFeePerGas: await this.provider.getGasPrice(),\n         maxPriorityFeePerGas: ethers.parseUnits('2', 'gwei'),\n         nonce: await this.provider.getTransactionCount(this.signerAddress),\n         chainId: this.chainId\n       };\n       return await this.signer.sendTransaction(tx);\n     }\n     ```\n\n4. **트랜잭션 처리 플로우 수정**\n   - processWithdrawal() 메서드에서 토큰 타입 확인 후 분기 처리\n   - 네이티브 토큰은 개별 트랜잭션으로만 처리\n   - ERC20 토큰은 기존 배치/단일 처리 로직 유지\n\n5. **잔액 검증 로직 업데이트**\n   - BalanceService에서 네이티브 토큰 잔액 확인 로직 추가\n   - provider.getBalance() 사용하여 네이티브 잔액 조회\n   - 가스비 계산 시 네이티브 토큰 전송은 21,000 gas 고정\n\n6. **데이터베이스 마이그레이션**\n   - WithdrawalRequest 테이블에 tokenType 컬럼 추가\n   - 기존 레코드는 모두 'ERC20'로 기본값 설정\n\n7. **에러 처리 강화**\n   - 네이티브 토큰 배치 전송 시도 시 명확한 에러 메시지\n   - 잔액 부족 시 가스비 포함 필요 금액 안내",
        "testStrategy": "1. **단위 테스트**\n   - 네이티브 토큰 식별 로직 테스트 (tokenAddress가 null, '0x0' 등)\n   - signNativeTransaction() 메서드 동작 검증\n   - 네이티브 토큰 잔액 조회 정확성 테스트\n\n2. **통합 테스트**\n   - API 엔드포인트에서 네이티브 토큰 출금 요청 수락 테스트\n   - 네이티브 토큰과 ERC20 토큰 혼합 요청 시나리오\n   - 배치 전송에서 네이티브 토큰 제외 검증\n\n3. **Hardhat 로컬 환경 테스트**\n   - 로컬 체인에서 실제 네이티브 토큰 전송 테스트\n   - 가스비 계산 정확성 검증\n   - 트랜잭션 확인 및 잔액 변화 추적\n\n4. **엣지 케이스 테스트**\n   - 네이티브 토큰 잔액이 정확히 가스비만큼인 경우\n   - 네이티브 토큰 배치 전송 시도 시 에러 처리\n   - 다양한 체인(Polygon, BSC, Ethereum)에서의 네이티브 토큰 처리\n\n5. **성능 테스트**\n   - 대량의 네이티브 토큰 개별 전송 처리 시간 측정\n   - ERC20 배치 전송 대비 처리량 비교",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "[BFS-40] 배치 트랜잭션 allowance 최적화 구현",
        "description": "Multicall3 배치 트랜잭션 실행 시 매번 approve 트랜잭션을 보내는 대신 기존 allowance를 확인하고 재사용하여 불필요한 트랜잭션을 줄이고 가스비와 처리 시간을 절약하는 최적화 시스템을 구현합니다.",
        "status": "done",
        "dependencies": [22, 15, 11],
        "priority": "medium",
        "details": "**구현 목표**\n- 현재 매 배치마다 실행되는 approve 트랜잭션을 최소화\n- allowance 상태를 추적하여 필요한 경우에만 approve 실행\n- 가스비 절감 및 트랜잭션 처리 시간 단축\n\n**1. Allowance 추적 시스템 구현**\n- signing-service에 AllowanceManager 클래스 생성\n- Redis를 사용한 allowance 캐싱 시스템 구현\n  ```typescript\n  interface AllowanceCache {\n    tokenAddress: string;\n    spenderAddress: string;\n    allowance: string;\n    lastUpdated: number;\n    blockNumber: number;\n  }\n  ```\n- 캐시 키 구조: `allowance:${chainId}:${tokenAddress}:${ownerAddress}:${spenderAddress}`\n\n**2. Allowance 체크 로직 구현**\n- 배치 실행 전 현재 allowance 확인\n- 온체인 allowance vs 캐시된 allowance 검증\n- 필요한 토큰 수량과 현재 allowance 비교\n  ```typescript\n  async checkAllowance(tokenAddress: string, amount: BigNumber): Promise<boolean> {\n    const currentAllowance = await this.getAllowance(tokenAddress);\n    return currentAllowance.gte(amount);\n  }\n  ```\n\n**3. 조건부 Approve 실행**\n- allowance가 부족한 경우에만 approve 트랜잭션 실행\n- Infinite approval vs 정확한 금액 approval 설정 옵션\n- approve 트랜잭션 실패 시 재시도 로직\n\n**4. Multicall3Service 수정**\n- prepareBatchTransaction() 메서드에 allowance 체크 로직 추가\n- approve 트랜잭션을 조건부로 배치에 포함\n- 배치 실행 후 allowance 캐시 업데이트\n\n**5. 안전장치 구현**\n- allowance 캐시 TTL 설정 (기본 1시간)\n- 블록 번호 기반 캐시 무효화\n- approve 트랜잭션 실패 시 전체 배치 중단\n- Emergency reset 기능 (캐시 전체 삭제)\n\n**6. 설정 옵션**\n- ALLOWANCE_OPTIMIZATION_ENABLED: 최적화 활성화 여부\n- INFINITE_APPROVAL_ENABLED: 무한 approval 사용 여부\n- ALLOWANCE_CACHE_TTL: 캐시 유효 시간\n- MIN_ALLOWANCE_BUFFER: 최소 여유 allowance (10%)\n\n**7. 모니터링 및 메트릭**\n- approve 트랜잭션 절감률 추적\n- 가스비 절감액 계산\n- allowance 캐시 히트률 모니터링\n- approve 트랜잭션 실패율 추적",
        "testStrategy": "**1. 단위 테스트**\n- AllowanceManager의 캐싱 로직 테스트\n- checkAllowance() 메서드의 정확성 검증\n- 캐시 TTL 및 무효화 로직 테스트\n- Infinite approval vs 정확한 금액 approval 테스트\n\n**2. 통합 테스트**\n- 첫 번째 배치: approve + multicall 실행 확인\n- 두 번째 배치: approve 스킵하고 multicall만 실행 확인\n- allowance 소진 시나리오: 자동 재approve 테스트\n- 다중 토큰 배치에서 선택적 approve 테스트\n\n**3. 시나리오 테스트**\n- 동일 토큰 연속 배치 처리 (approve 1회만 실행)\n- allowance 부족 상황 자동 감지 및 처리\n- 캐시 만료 후 allowance 재확인\n- approve 트랜잭션 실패 시 배치 중단 확인\n\n**4. 성능 테스트**\n- 최적화 전후 가스비 비교 (예상 절감률 30-50%)\n- 배치 처리 시간 비교 (approve 제외로 인한 속도 향상)\n- 캐시 히트률 측정 (목표 80% 이상)\n\n**5. 엣지 케이스**\n- approve 트랜잭션 pending 중 배치 실행 방지\n- 네트워크 재구성 시 캐시 무효화\n- 동시 다중 배치 실행 시 allowance 경합 조건\n- 토큰 컨트랙트의 특수한 approve 구현 대응",
        "subtasks": []
      },
      {
        "id": 25,
        "title": "[BFS-25] 프로덕션 allowance 추적 시스템 및 아키텍처 개선",
        "description": "signing service는 트랜잭션 서명만 담당하고 approve TX는 broadcaster가 처리하도록 아키텍처를 개선하며, 펜딩 트랜잭션의 allowance 소비량을 추적하여 부족 시 큐잉하는 프로덕션 환경용 allowance 관리 시스템을 구현합니다.",
        "details": "**1. 아키텍처 개선**\n- signing-service에서 approve 트랜잭션 로직을 제거하고 서명 기능만 유지\n- tx-processor(broadcaster)에 approve 트랜잭션 처리 책임 이전\n- 트랜잭션 타입별 처리 분리: APPROVE, MULTICALL 타입 추가\n\n**2. Allowance 추적 시스템**\n- GlobalAllowanceTracker 클래스 구현 (Redis 기반)\n- 펜딩 트랜잭션의 allowance 소비량 예약 시스템\n- 키 구조: `pending_allowance:${chainId}:${tokenAddress}:${spenderAddress}`\n- 실시간 allowance 상태 동기화 및 블록체인 상태와의 일치성 보장\n\n**3. Queue 기반 트랜잭션 관리**\n- allowance 부족 시 트랜잭션을 대기 큐에 저장\n- approve 트랜잭션 완료 후 대기 중인 트랜잭션 자동 재개\n- 큐 우선순위 관리 (고액 트랜잭션 우선 처리)\n\n**4. 블록체인 상태 동기화**\n- 블록 이벤트 리스너를 통한 allowance 변경 감지\n- 트랜잭션 컨펌 후 캐시 업데이트\n- 데드락 방지를 위한 타임아웃 및 정리 로직\n\n**5. 프로덕션 환경 고려사항**\n- 동시성 제어를 위한 Redis 분산 락 구현\n- 메트릭 수집 (allowance 소진율, 대기 큐 길이)\n- 장애 복구 시나리오 처리",
        "testStrategy": "**1. 아키텍처 분리 테스트**\n- signing-service에서 approve 로직 제거 검증\n- broadcaster의 approve 트랜잭션 처리 능력 테스트\n- 트랜잭션 타입별 라우팅 정확성 검증\n\n**2. Allowance 추적 정확성 테스트**\n- 펜딩 트랜잭션 allowance 예약/해제 테스트\n- 동시 트랜잭션 처리 시 allowance 경합 상황 테스트\n- 블록체인 상태와 캐시 동기화 정확성 검증\n\n**3. 큐잉 시스템 테스트**\n- allowance 부족 시 대기 큐 저장 테스트\n- approve 완료 후 대기 트랜잭션 자동 재개 테스트\n- 큐 우선순위 및 순서 보장 테스트\n\n**4. 동시성 및 성능 테스트**\n- 다중 사용자 동시 트랜잭션 처리 테스트\n- Redis 분산 락 동작 검증\n- 대용량 트랜잭션 처리 성능 테스트\n\n**5. 장애 복구 테스트**\n- 네트워크 단절 시 상태 복구 테스트\n- 서비스 재시작 후 펜딩 상태 복원 테스트\n- 블록체인 노드 장애 시 fallback 처리 테스트",
        "status": "pending",
        "dependencies": [24, 15, 11],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 26,
        "title": "[BFS-44] Signing Service 단순화 및 안정성 개선",
        "description": "Balance와 Allowance는 충분하다고 가정하고 복잡한 사전 검증을 제거하여 서비스를 단순하게 유지합니다. Approve TX는 모두 제거하고, 오류 발생 시에만 대기 및 복구하는 방식으로 구현합니다.",
        "status": "pending",
        "dependencies": [25, 24, 15, 11],
        "priority": "medium",
        "details": "**1. 사전 검증 로직 제거**\n- signing-service에서 BalanceService 및 AllowanceManager의 사전 검증 로직 제거\n- 트랜잭션 서명 전 잔액/allowance 확인 단계 생략\n- Redis 캐싱 기반 잔액 추적 시스템 비활성화\n- 복잡한 allowance 추적 및 예약 시스템 제거\n\n**2. Approve 트랜잭션 완전 제거**\n- MulticallService에서 approve 트랜잭션 생성 로직 제거\n- 배치 트랜잭션 처리 시 approve 단계 생략\n- AllowanceManager.checkAllowance() 호출 제거\n- 모든 토큰이 충분한 allowance를 가지고 있다고 가정\n\n**3. 오류 기반 처리 방식 구현**\n- 트랜잭션 실행 후 실패 결과를 기반으로 처리\n- allowance 부족으로 실패 시 approve 트랜잭션 자동 생성 및 재시도\n- 잔액 부족으로 실패 시 대기 큐에 저장 후 지연 처리\n- 에러 코드 분석을 통한 실패 원인 식별 (ERC20: insufficient allowance, insufficient balance)\n\n**4. 단순화된 트랜잭션 플로우**\n- signing-service: 서명 요청 → 즉시 서명 → 결과 반환\n- tx-processor: 트랜잭션 전송 → 실패 시 복구 로직 실행\n- 성공 케이스에서는 최소한의 처리로 빠른 응답\n- 실패 케이스에서만 복구 메커니즘 동작\n\n**5. 복구 메커니즘 구현**\n- TransactionRecoveryService 클래스 생성\n- 실패 트랜잭션 분석 및 자동 복구 시도\n- approve 후 원본 트랜잭션 재실행\n- 최대 재시도 횟수 제한 (3회)\n- 복구 불가능한 경우 DLQ(Dead Letter Queue)로 이동",
        "testStrategy": "**1. 단순화 검증 테스트**\n- signing-service에서 잔액/allowance 검증 로직 제거 확인\n- approve 트랜잭션 생성 코드 완전 제거 검증\n- Redis 캐싱 시스템 비활성화 테스트\n- 트랜잭션 서명 속도 개선 측정 (이전 대비 50% 이상 단축 목표)\n\n**2. 오류 기반 처리 테스트**\n- allowance 부족 시나리오에서 자동 approve + 재시도 테스트\n- 잔액 부족 시나리오에서 대기 큐 저장 테스트\n- 다양한 에러 코드에 대한 복구 로직 정확성 검증\n- 최대 재시도 횟수 도달 시 DLQ 처리 테스트\n\n**3. 성능 및 안정성 테스트**\n- 성공 케이스에서의 처리 시간 단축 검증\n- 높은 성공률 환경에서의 시스템 부하 감소 측정\n- 실패율이 높은 환경에서의 복구 메커니즘 안정성 테스트\n- 동시 다중 트랜잭션 처리 시 복구 로직 충돌 방지 테스트\n\n**4. 통합 테스트**\n- Hardhat 로컬 환경에서 충분한 allowance 상황 시뮬레이션\n- 실제 트랜잭션 실행 및 성공률 측정\n- 복구 메커니즘 동작 시 전체 플로우 검증",
        "subtasks": [
          {
            "id": 1,
            "title": "API Server에 최대 전송 금액 검증 로직 추가",
            "description": "withdrawal request 엔드포인트에서 tokens.config.json의 maxTransferAmount 설정을 참조하여 요청 금액이 초과할 경우 400 Bad Request 에러를 반환하는 유효성 검증을 구현합니다.",
            "status": "done",
            "dependencies": [],
            "details": "TokenConfigService를 통해 토큰별 최대 전송 금액 조회, 단일 전송 및 배치 전송 모두에 대해 개별 금액 검증 수행, 검증 실패 시 'Transfer amount exceeds maximum allowed limit' 메시지와 함께 적절한 에러 응답 반환, WithdrawalRequestValidator에 최대 금액 검증 로직 통합, 배치 전송의 경우 각 개별 요청에 대해 최대 금액 검증 적용",
            "testStrategy": "토큰별 최대 전송 금액 초과 시 400 에러 응답 테스트, 단일/배치 전송에서 개별 금액 검증 테스트, 유효한 금액 범위에서 정상 처리 테스트"
          },
          {
            "id": 2,
            "title": "사전 검증 로직 제거 및 의존성 정리",
            "description": "signing-service에서 BalanceService, AllowanceManager의 사전 검증 로직을 완전히 제거하고 관련 의존성을 정리합니다.",
            "status": "done",
            "dependencies": [1],
            "details": "TransactionSigner에서 BalanceService.checkBalance() 및 AllowanceManager.checkAllowance() 호출 제거, Redis 캐싱 기반 잔액 추적 시스템 비활성화, signing-worker.ts에서 사전 검증 단계 생략하도록 수정, 사용하지 않는 import 및 의존성 정리, 환경 변수에서 잔액 검증 관련 설정 제거\n<info added on 2025-07-31T06:11:00.598Z>\n사전 검증 로직 분석 완료: BalanceService, AllowanceManager 클래스 및 관련 메서드들이 이미 제거된 상태임을 확인. Redis 기반 잔액 추적 시스템도 비활성화됨. 현재 config에 남아있는 allowance 관련 설정(allowanceStrategy, allowanceMultiplier, allowanceAmount)은 approve 트랜잭션 최적화용이며, Task 26.3에서 approve 로직과 함께 제거 예정. 해당 서브태스크는 실질적으로 완료된 상태로 판단됨.\n</info added on 2025-07-31T06:11:00.598Z>",
            "testStrategy": "사전 검증 로직 제거 후 서명 속도 개선 측정, 트랜잭션 서명 과정에서 잔액/allowance 검증 호출이 없는지 확인"
          },
          {
            "id": 3,
            "title": "Approve 트랜잭션 생성 로직 완전 제거",
            "description": "MulticallService와 관련 서비스에서 approve 트랜잭션을 생성하는 모든 로직을 제거합니다.",
            "status": "done",
            "dependencies": [2],
            "details": "MulticallService.buildTransaction()에서 approve 트랜잭션 생성 코드 제거, AllowanceManager.checkAllowance() 메서드 호출 제거, 배치 트랜잭션 처리 시 approve 단계 완전 생략, APPROVE 트랜잭션 타입 관련 로직 제거, 모든 토큰이 충분한 allowance를 가지고 있다고 가정하는 주석 추가\n<info added on 2025-07-31T06:17:31.272Z>\n구현 완료:\n- transaction-signer.ts와 multicall.service.ts에서 ERC20_ABI의 'approve' 함수 제거\n- 시작 시 MAX approval을 생성하던 initializeMaxApprovals() 메서드 삭제\n- approve 트랜잭션을 전송하던 approveToken() 메서드 삭제\n- approval 금액을 계산하던 calculateOptimalAllowance() 메서드 삭제\n- signBatchTransaction()에서 approve 트랜잭션 호출 제거\n- approve 로직이 제거되고 충분한 allowance를 가정한다는 주석 추가\n- allowance 최적화 설정 제거 (allowanceStrategy, allowanceMultiplier, allowanceAmount)\n- env.example에서 BATCH_ALLOWANCE_* 환경 변수 제거\n- allowance 관련 설정을 제거하도록 테스트 파일 업데이트\n- 모든 lint 오류 수정 완료 및 빌드 성공\n</info added on 2025-07-31T06:17:31.272Z>",
            "testStrategy": "approve 트랜잭션이 생성되지 않는지 확인, 배치 트랜잭션에서 approve 단계가 생략되는지 테스트"
          },
          {
            "id": 4,
            "title": "트랜잭션 실패 에러 분석 시스템 구현",
            "description": "트랜잭션 실행 후 실패 결과를 분석하여 실패 원인을 식별하는 시스템을 구현합니다.",
            "status": "pending",
            "dependencies": [3],
            "details": "TransactionErrorAnalyzer 클래스 생성, ERC20 표준 에러 코드 분석 (insufficient allowance, insufficient balance), 컨트랙트 revert 메시지 파싱 로직, 에러 타입별 분류 시스템 (ALLOWANCE_ERROR, BALANCE_ERROR, GAS_ERROR, UNKNOWN_ERROR), ethers.js 에러 객체에서 원인 추출 메서드 구현",
            "testStrategy": "다양한 실패 시나리오에서 에러 분석 정확성 테스트, allowance 부족과 잔액 부족 시나리오 구분 테스트"
          },
          {
            "id": 5,
            "title": "오류 기반 자동 복구 메커니즘 구현",
            "description": "실패 분석 결과에 따라 approve 트랜잭션 생성 및 재시도, 또는 대기 큐 저장을 처리하는 복구 시스템을 구현합니다.",
            "status": "pending",
            "dependencies": [4],
            "details": "TransactionRecoveryService 클래스 생성, allowance 부족 시 approve 트랜잭션 자동 생성 로직, approve 완료 후 원본 트랜잭션 재실행 메커니즘, 잔액 부족 시 대기 큐(Redis)에 저장하는 로직, 최대 재시도 횟수 제한 (3회) 및 재시도 간격 설정, 복구 불가능한 경우 DLQ(Dead Letter Queue)로 이동 처리",
            "testStrategy": "allowance 부족 시 자동 approve 및 재실행 테스트, 잔액 부족 시 대기 큐 저장 테스트, 최대 재시도 초과 시 DLQ 이동 테스트"
          },
          {
            "id": 6,
            "title": "단순화된 트랜잭션 플로우 통합 및 테스트",
            "description": "새로운 오류 기반 처리 방식을 기존 시스템에 통합하고 전체 플로우를 검증합니다.",
            "status": "pending",
            "dependencies": [5],
            "details": "signing-service와 tx-processor 간의 새로운 플로우 통합, 성공 케이스에서 최소한의 처리로 빠른 응답 보장, 실패 케이스에서만 복구 메커니즘 동작하도록 조건부 처리, WithdrawalRequest 상태 관리 업데이트 (RECOVERY_PENDING, RECOVERY_FAILED 상태 추가), 전체 시스템의 성능 및 안정성 검증을 위한 통합 테스트 구현",
            "testStrategy": "전체 플로우 통합 테스트, 성공/실패 시나리오별 응답 시간 측정, 복구 메커니즘 동작 검증, 시스템 부하 테스트를 통한 안정성 확인"
          }
        ]
      },
      {
        "id": 27,
        "title": "[BFS-43] Account Manager 서비스 구현",
        "description": "메인 계정에서 서브 계정으로 자동 잔액 밸런싱을 수행하는 Account Manager 서비스를 구현하여 서브 계정 잔액 모니터링, 임계값 기반 자동 충전, 배치 처리를 통한 가스비 절감 기능을 제공합니다.",
        "details": "**구현 목표**\n- 서브 계정 잔액을 지속적으로 모니터링하고 임계값 도달 시 자동 충전\n- 배치 처리를 통한 가스비 최적화 및 메인 계정 잔액 부족 시 알림\n- ManagedAccount 및 BalanceTransfer 모델을 통한 계정 관리 시스템\n\n**1. 데이터베이스 모델 구현**\n- ManagedAccount 모델 추가\n  ```typescript\n  model ManagedAccount {\n    id          String   @id @default(cuid())\n    address     String   @unique\n    name        String\n    threshold   Decimal  // 최소 잔액 임계값\n    targetAmount Decimal // 충전 목표 금액\n    isActive    Boolean  @default(true)\n    mainAccount String   // 메인 계정 주소\n    createdAt   DateTime @default(now())\n    updatedAt   DateTime @updatedAt\n    balanceTransfers BalanceTransfer[]\n  }\n  ```\n- BalanceTransfer 모델 추가\n  ```typescript\n  model BalanceTransfer {\n    id              String         @id @default(cuid())\n    fromAddress     String\n    toAddress       String\n    amount          Decimal\n    transactionHash String?\n    status          TransferStatus @default(PENDING)\n    managedAccount  ManagedAccount @relation(fields: [toAddress], references: [address])\n    createdAt       DateTime       @default(now())\n    updatedAt       DateTime       @updatedAt\n  }\n  \n  enum TransferStatus {\n    PENDING\n    PROCESSING\n    COMPLETED\n    FAILED\n  }\n  ```\n\n**2. Account Manager 서비스 구현**\n- Nx를 사용하여 account-manager 앱 생성 (nx g @nx/node:app account-manager)\n- AccountBalanceMonitor 클래스로 서브 계정 잔액 모니터링\n- BalanceTransferService 클래스로 자동 충전 로직 구현\n- Redis를 사용한 잔액 캐싱 및 모니터링 상태 관리\n- 배치 처리를 위한 BatchTransferProcessor 구현\n\n**3. 잔액 모니터링 시스템**\n- 주기적인 서브 계정 잔액 확인 (30초 간격)\n- 임계값 도달 시 자동 충전 트리거\n- 메인 계정 잔액 확인 및 부족 시 알림 발송\n- 잔액 변화 이력 추적 및 로깅\n\n**4. 배치 처리 최적화**\n- 동시간대 여러 충전 요청을 배치로 묶어 처리\n- Multicall3을 활용한 배치 전송으로 가스비 절감\n- 배치 크기 최적화 및 가스 한도 내 처리\n- 실패한 전송에 대한 개별 재시도 로직\n\n**5. 알림 시스템**\n- 메인 계정 잔액 부족 시 이메일/Slack 알림\n- 충전 실패 시 관리자 알림\n- 비정상적인 잔액 소모 패턴 감지 및 알림\n\n**6. API 엔드포인트**\n- GET /account-manager/accounts - 관리 계정 목록 조회\n- POST /account-manager/accounts - 새 관리 계정 등록\n- PUT /account-manager/accounts/:id - 계정 설정 업데이트\n- GET /account-manager/transfers - 잔액 이전 내역 조회\n- POST /account-manager/transfers/manual - 수동 잔액 이전",
        "testStrategy": "**1. 단위 테스트**\n- ManagedAccount 및 BalanceTransfer 모델 CRUD 테스트\n- AccountBalanceMonitor의 잔액 확인 로직 테스트\n- BalanceTransferService의 충전 로직 테스트\n- 임계값 도달 감지 및 트리거 테스트\n- 배치 처리 로직 및 최적화 테스트\n\n**2. 통합 테스트**\n- 실제 Polygon 테스트넷에서 잔액 모니터링 테스트\n- 임계값 도달 시 자동 충전 플로우 테스트\n- 메인 계정 잔액 부족 시나리오 테스트\n- 배치 전송 성공/실패 시나리오 테스트\n- 동시 다중 계정 모니터링 테스트\n\n**3. 성능 테스트**\n- 대량 계정(100개+) 모니터링 성능 테스트\n- 배치 처리 효율성 및 가스비 절감 검증\n- Redis 캐싱 성능 및 메모리 사용량 테스트\n- 모니터링 주기별 시스템 부하 테스트\n\n**4. 장애 복구 테스트**\n- 네트워크 장애 시 재시도 로직 테스트\n- RPC 노드 실패 시 폴백 처리 테스트\n- 서비스 재시작 시 상태 복구 테스트\n- 부분 실패한 배치 전송 복구 테스트",
        "status": "pending",
        "dependencies": [12, 15],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "데이터베이스 모델 및 마이그레이션 구현",
            "description": "ManagedAccount와 BalanceTransfer 모델을 정의하고 Prisma 스키마를 업데이트하여 계정 관리 시스템의 데이터 구조를 구축합니다.",
            "dependencies": [],
            "details": "Prisma 스키마에 ManagedAccount 모델 추가 (id, address, name, threshold, targetAmount, isActive, mainAccount, timestamps), BalanceTransfer 모델 추가 (id, fromAddress, toAddress, amount, transactionHash, status, timestamps), TransferStatus enum 정의 (PENDING, PROCESSING, COMPLETED, FAILED), 모델 간 관계 설정 (BalanceTransfer -> ManagedAccount), 필요한 인덱스 추가 (address unique index, status index for queries)",
            "status": "pending",
            "testStrategy": "Prisma 스키마 유효성 검증 테스트, 모델 CRUD 작업 단위 테스트, 관계 설정 및 Cascade 동작 테스트, 데이터 타입 및 제약 조건 검증 테스트"
          },
          {
            "id": 2,
            "title": "Account Manager 앱 초기 구조 및 서비스 계층 구현",
            "description": "Nx를 사용하여 account-manager 앱을 생성하고 핵심 서비스 클래스들을 구현하여 계정 관리의 기본 비즈니스 로직을 구축합니다.",
            "dependencies": ["27.1"],
            "details": "Nx 명령어로 account-manager 앱 생성 (nx g @nx/node:app account-manager), AccountBalanceMonitor 클래스 구현 (잔액 조회, 임계값 비교, 모니터링 스케줄러), BalanceTransferService 클래스 구현 (충전 로직, 트랜잭션 생성, 상태 관리), BatchTransferProcessor 클래스 구현 (배치 큐 관리, 배치 크기 최적화, Multicall3 통합), Redis 클라이언트 설정 및 캐싱 레이어 구현, 환경 변수 설정 (MONITORING_INTERVAL, BATCH_SIZE, GAS_LIMIT 등)",
            "status": "pending",
            "testStrategy": "각 서비스 클래스의 메서드 단위 테스트, Redis 연결 및 캐싱 동작 테스트, 환경 변수 로딩 및 검증 테스트, 서비스 간 의존성 주입 테스트"
          },
          {
            "id": 3,
            "title": "잔액 모니터링 및 자동 충전 시스템 구현",
            "description": "주기적으로 서브 계정의 잔액을 확인하고 임계값 도달 시 자동으로 충전을 트리거하는 모니터링 시스템을 구현합니다.",
            "dependencies": ["27.2"],
            "details": "30초 간격 모니터링 스케줄러 구현 (node-cron 또는 bull 사용), Web3/Ethers.js를 통한 실시간 잔액 조회 로직, 임계값 비교 및 충전 필요성 판단 알고리즘, 메인 계정 잔액 확인 및 충분성 검증, 충전 트리거 이벤트 발생 및 큐 등록, Redis를 활용한 잔액 캐싱 (TTL 설정), 모니터링 상태 추적 (last_checked, next_check 등), 동시성 제어를 위한 분산 락 구현",
            "status": "pending",
            "testStrategy": "스케줄러 동작 및 주기 정확성 테스트, 잔액 조회 API 모킹 및 임계값 시나리오 테스트, 메인 계정 잔액 부족 시나리오 테스트, Redis 캐시 만료 및 갱신 테스트, 분산 락 경합 상황 테스트"
          },
          {
            "id": 4,
            "title": "배치 처리 최적화 및 가스비 절감 시스템 구현",
            "description": "여러 충전 요청을 배치로 묶어 Multicall3을 통해 처리하여 가스비를 절감하고 처리 효율을 높이는 시스템을 구현합니다.",
            "dependencies": ["27.3"],
            "details": "배치 큐 시스템 구현 (Bull Queue 활용), 시간 윈도우 기반 배치 수집 (예: 30초 동안 요청 수집), Multicall3 컨트랙트 인터페이스 구현, 배치 크기 최적화 알고리즘 (가스 한도 고려), 배치 트랜잭션 구성 및 가스 추정, 개별 전송 실패 처리 및 재시도 로직, 배치 처리 결과 파싱 및 개별 상태 업데이트, 가스비 절감 메트릭 수집 및 로깅",
            "status": "pending",
            "testStrategy": "다양한 배치 크기에 대한 가스 소비 테스트, Multicall3 통합 테스트 (성공/부분실패 시나리오), 배치 큐 동작 및 시간 윈도우 테스트, 재시도 로직 및 지수 백오프 테스트, 가스비 절감 효과 측정 테스트"
          },
          {
            "id": 5,
            "title": "API 엔드포인트 및 알림 시스템 구현",
            "description": "Account Manager 기능을 제어하고 모니터링할 수 있는 RESTful API와 중요 이벤트에 대한 알림 시스템을 구현합니다.",
            "dependencies": ["27.4"],
            "details": "Express Router 설정 및 API 엔드포인트 구현 (GET /accounts, POST /accounts, PUT /accounts/:id, GET /transfers, POST /transfers/manual), 요청 검증 미들웨어 구현 (Joi 또는 Zod 사용), 알림 서비스 구현 (EmailService, SlackService 인터페이스), 메인 계정 잔액 부족 알림 로직, 충전 실패 알림 및 에러 상세 정보 포함, 비정상 패턴 감지 알고리즘 (급격한 잔액 소모 등), 알림 템플릿 및 포맷팅 시스템, 알림 전송 이력 및 재시도 관리",
            "status": "pending",
            "testStrategy": "각 API 엔드포인트 통합 테스트, 요청 검증 및 에러 핸들링 테스트, 알림 서비스 모킹 및 전송 검증 테스트, 알림 템플릿 렌더링 테스트, 비정상 패턴 감지 알고리즘 정확성 테스트"
          }
        ]
      },
      {
        "id": 28,
        "title": "[BFS-41] 프로덕션급 로깅 라이브러리 마이그레이션",
        "description": "현재 커스텀 Logger를 winston 또는 pino 같은 프로덕션급 로깅 라이브러리로 대체하여 구조화된 로깅, 설정 가능한 로그 레벨, 다양한 출력 옵션을 지원하도록 시스템을 개선합니다.",
        "status": "done",
        "dependencies": [11, 15],
        "priority": "medium",
        "details": "**구현 목표**\n- 현재 커스텀 Logger 클래스를 프로덕션급 로깅 라이브러리로 완전 대체\n- 구조화된 로깅으로 로그 분석 및 모니터링 개선\n- 환경별 로그 레벨 설정 및 다양한 출력 대상 지원\n\n**1. 로깅 라이브러리 선택 및 설치**\n- winston vs pino 성능 및 기능 비교 분석\n- 선택된 라이브러리 설치 및 기본 설정\n- TypeScript 타입 정의 설치\n\n**2. 통합 Logger 서비스 구현**\n- packages/shared/src/services에 LoggerService 클래스 생성\n- 환경 변수 기반 로그 레벨 설정 (LOG_LEVEL)\n- 구조화된 로그 포맷 정의 (JSON 형태)\n```typescript\ninterface LogContext {\n  service: string;\n  requestId?: string;\n  userId?: string;\n  transactionHash?: string;\n  chainId?: number;\n  metadata?: Record<string, any>;\n}\n```\n\n**3. 출력 대상 설정**\n- 개발 환경: 콘솔 출력 (색상 포함)\n- 프로덕션 환경: 파일 출력 + 외부 서비스 연동\n- 로그 파일 로테이션 설정 (daily, 최대 크기 제한)\n- 에러 로그 별도 파일 저장\n\n**4. 기존 Logger 대체**\n- withdrawal-api, tx-processor, tx-monitor 앱들의 기존 Logger import 교체\n- console.log/error 호출을 구조화된 로그로 변환\n- 중요 비즈니스 로직에 추적 가능한 로그 추가\n- 민감한 정보(개인키, 비밀번호) 로깅 방지 필터 구현\n\n**5. 로그 레벨 및 필터링**\n- ERROR: 시스템 오류, 예외 상황\n- WARN: 경고, 잠재적 문제\n- INFO: 일반적인 비즈니스 로직 실행\n- DEBUG: 상세한 디버깅 정보\n- 환경별 기본 로그 레벨 설정 (개발: DEBUG, 프로덕션: INFO)\n\n**6. 성능 최적화**\n- 비동기 로깅으로 메인 스레드 블로킹 방지\n- 로그 버퍼링 및 배치 처리\n- 고빈도 로그에 대한 샘플링 적용",
        "testStrategy": "**1. 로깅 시스템 검증 테스트**\n- LoggerService 인스턴스 생성 및 기본 설정 테스트\n- 각 로그 레벨별 출력 정확성 검증\n- 구조화된 로그 포맷 JSON 검증\n- 환경 변수별 로그 레벨 동적 변경 테스트\n\n**2. 출력 대상 테스트**\n- 콘솔 출력 형식 및 색상 표시 확인\n- 파일 출력 기능 및 로테이션 정책 테스트\n- 에러 로그 별도 파일 저장 검증\n- 로그 파일 크기 제한 및 아카이브 기능 테스트\n\n**3. 보안 및 필터링 테스트**\n- 민감한 정보 자동 마스킹 기능 검증\n- 개인키, 비밀번호 등이 로그에 노출되지 않는지 확인\n- 로그 컨텍스트 정보 정확성 검증 (requestId, userId 등)\n\n**4. 성능 테스트**\n- 고빈도 로깅 상황에서 메인 스레드 블로킹 없음 확인\n- 로그 버퍼링 및 배치 처리 성능 측정\n- 기존 커스텀 Logger 대비 성능 개선 측정\n\n**5. 통합 테스트**\n- 모든 마이크로서비스에서 동일한 로그 포맷 출력 확인\n- 분산 환경에서 requestId 추적 가능성 검증\n- 로그 분석 도구와의 호환성 테스트",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "[BFS-42] NonceCacheService의 Dependency Injection 개선",
        "description": "NonceCacheService 생성자에서 Logger를 필수 파라미터로 변경하고 기본 Logger 인스턴스 생성 로직을 제거하여 의존성 주입 패턴을 개선합니다.",
        "status": "pending",
        "dependencies": [28, 15],
        "priority": "medium",
        "details": "**구현 목표**\n- NonceCacheService의 생성자에서 Logger 의존성을 명시적으로 주입받도록 변경\n- 클래스 내부에서 Logger 인스턴스를 직접 생성하는 로직 제거\n- 의존성 역전 원칙(DIP)을 준수하여 테스트 가능성과 유연성 향상\n\n**1. NonceCacheService 생성자 수정**\n- 현재 생성자에서 Logger 매개변수를 선택적(optional)에서 필수(required)로 변경\n- 기본 Logger 인스턴스 생성 로직 제거\n```typescript\n// Before\nconstructor(private logger: Logger = new Logger()) {}\n\n// After\nconstructor(private logger: Logger) {}\n```\n\n**2. 호출부 코드 수정**\n- NonceCacheService를 사용하는 모든 클래스에서 Logger 인스턴스를 명시적으로 전달\n- signing-service, tx-processor 등에서 LoggerService 인스턴스 주입\n- 테스트 코드에서 Mock Logger 주입 가능하도록 수정\n\n**3. 타입 안전성 개선**\n- Logger 인터페이스 타입 정의 확인 및 필요시 개선\n- 의존성 주입 컨테이너 사용 시 Logger 등록 설정",
        "testStrategy": "**1. 생성자 변경 테스트**\n- Logger 없이 NonceCacheService 인스턴스 생성 시 TypeScript 컴파일 오류 발생 확인\n- 올바른 Logger 인스턴스로 생성 시 정상 작동 확인\n- Mock Logger를 주입하여 로그 메서드 호출 여부 검증\n\n**2. 의존성 주입 테스트**\n- 실제 LoggerService 인스턴스 주입 시 정상 로깅 동작 확인\n- 다양한 Logger 구현체(winston, pino 등) 주입 테스트\n- 로그 레벨별 출력 정확성 검증\n\n**3. 통합 테스트**\n- signing-service에서 NonceCacheService 사용 시 정상 작동 확인\n- tx-processor에서 논스 캐싱 기능과 로깅 기능 동시 검증\n- 에러 상황에서 적절한 로그 출력 여부 확인\n\n**4. 리팩토링 검증**\n- 모든 NonceCacheService 사용처에서 Logger 주입 확인\n- 기존 기능 동작에 영향 없음을 확인하는 회귀 테스트",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "[BFS-45] GitHub Actions CI/CD 파이프라인에 코드 품질 검사 단계 추가",
        "description": "PR과 main 브랜치에서 자동으로 실행되는 코드 품질 검사 파이프라인을 구성하여 lint, typecheck, depcheck, test, format 검사를 포함한 포괄적인 품질 관리 시스템을 구현합니다.",
        "status": "review",
        "dependencies": [28],
        "priority": "medium",
        "jiraKey": "BFS-45",
        "details": "**1. GitHub Actions 워크플로우 파일 생성**\n- `.github/workflows/ci.yml` 생성\n- PR 생성/업데이트 및 main 브랜치 push 시 트리거 설정\n- Node.js 18.x 환경 설정 및 의존성 캐싱 구성\n\n**2. 코드 품질 검사 단계 구현**\n- ESLint를 통한 코드 스타일 및 품질 검사 (`npm run lint`)\n- TypeScript 컴파일러를 통한 타입 검사 (`npm run typecheck`)\n- depcheck를 통한 미사용 의존성 검사\n- Jest를 통한 단위/통합 테스트 실행 (`npm test`)\n- Prettier를 통한 코드 포맷팅 검사 (`npm run format:check`)\n\n**3. 실패 처리 및 보고 시스템**\n- 각 단계별 실패 시 워크플로우 중단 설정\n- PR에 검사 결과 상태 표시 및 코멘트 추가\n- 테스트 커버리지 리포트 생성 및 아티팩트 저장\n- Slack 알림 연동 (선택사항)\n\n**4. 성능 최적화**\n- npm 캐시 설정으로 의존성 설치 시간 단축\n- 병렬 실행 가능한 작업들을 matrix 전략으로 구성\n- 조건부 실행으로 불필요한 작업 스킵",
        "testStrategy": "**1. 워크플로우 트리거 테스트**\n- 새 PR 생성 시 CI 파이프라인 자동 실행 확인\n- main 브랜치 push 시 파이프라인 실행 확인\n- PR 업데이트 시 재실행 동작 검증\n\n**2. 각 품질 검사 단계 검증**\n- 의도적으로 lint 오류를 발생시켜 워크플로우 실패 확인\n- TypeScript 타입 오류 시나리오에서 typecheck 실패 테스트\n- 미사용 의존성 추가 후 depcheck 감지 능력 확인\n- 테스트 실패 시나리오에서 전체 워크플로우 중단 확인\n- 포맷팅 오류 시 format 검사 실패 테스트\n\n**3. 성능 및 안정성 테스트**\n- 캐시 적용으로 두 번째 실행 시 속도 개선 확인\n- 동시 다중 PR에서 워크플로우 안정성 테스트\n- 네트워크 장애 시나리오에서 재시도 메커니즘 검증\n- 아티팩트 생성 및 다운로드 기능 확인",
        "subtasks": [
          {
            "id": 1,
            "title": ".github/workflows/ci.yml 워크플로우 파일 생성 및 기본 설정",
            "description": "GitHub Actions CI 파이프라인의 기본 구조를 설정하고 Node.js 환경 및 의존성 캐싱을 구성합니다.",
            "dependencies": [],
            "details": ".github/workflows/ 디렉토리 생성, ci.yml 파일 작성, PR 및 main 브랜치 트리거 설정, Node.js 18.x 환경 설정, npm 의존성 캐싱 구성, checkout 및 setup-node 액션 추가\n<info added on 2025-08-03T01:52:16.944Z>\nGitHub Actions CI 워크플로우 파일 생성 완료. .github/workflows/ci.yml 파일에 PR 및 main 브랜치 트리거 설정, Node.js 18.x 환경 구성, npm 캐싱 추가. code-quality, test, build 세 개의 작업으로 구성된 기본 워크플로우 구조 구현.\n</info added on 2025-08-03T01:52:16.944Z>",
            "status": "done",
            "testStrategy": "새 PR 생성 및 main 브랜치 push로 워크플로우 트리거 확인, Node.js 환경 및 의존성 설치 성공 여부 검증"
          },
          {
            "id": 2,
            "title": "ESLint 및 TypeScript 코드 품질 검사 단계 구현",
            "description": "코드 스타일 검사를 위한 ESLint와 타입 안전성 검사를 위한 TypeScript 컴파일러 단계를 추가합니다.",
            "dependencies": ["30.1"],
            "details": "npm run lint 명령어를 통한 ESLint 검사 단계 추가, npm run typecheck 명령어를 통한 TypeScript 컴파일 검사 추가, 각 단계별 실패 시 워크플로우 중단 설정, 에러 출력 형식 최적화\n<info added on 2025-08-03T01:52:40.267Z>\nNx 모노레포 환경에서 모든 프로젝트에 걸쳐 검사를 실행하는 Nx 기반 명령어로 구현 완료. code-quality 작업에서 'npm run lint'와 'npm run typecheck' 명령어가 추가되어 전체 워크스페이스의 코드 품질을 일괄 검사합니다.\n</info added on 2025-08-03T01:52:40.267Z>",
            "status": "done",
            "testStrategy": "의도적인 lint 오류 및 TypeScript 타입 오류 시나리오로 검사 실패 및 워크플로우 중단 확인"
          },
          {
            "id": 3,
            "title": "의존성 검사 및 코드 포맷팅 검증 단계 추가",
            "description": "미사용 의존성 검사를 위한 depcheck와 코드 포맷팅 검사를 위한 Prettier 단계를 구현합니다.",
            "dependencies": ["30.2"],
            "details": "depcheck 패키지 설치 및 npm script 추가, 미사용 의존성 검사 단계 구현, npm run format:check 명령어를 통한 Prettier 포맷팅 검사 추가, 각 검사별 상세 에러 리포트 설정\n<info added on 2025-08-03T01:53:04.258Z>\n의존성 검사는 `continue-on-error: true` 옵션을 사용하여 검사 실패 시에도 워크플로우가 계속 진행되도록 설정됨. 코드 포맷팅 검증은 Prettier를 실행한 후 `git diff --exit-code` 명령어로 커밋되지 않은 포맷팅 변경사항이 있는지 확인하여 포맷팅 일관성을 보장함.\n</info added on 2025-08-03T01:53:04.258Z>",
            "status": "done",
            "testStrategy": "미사용 의존성 추가 후 depcheck 감지 능력 확인, 의도적인 포맷팅 오류로 format 검사 실패 테스트"
          },
          {
            "id": 4,
            "title": "테스트 실행 및 커버리지 리포트 생성 단계 구현",
            "description": "Jest 테스트 실행과 테스트 커버리지 리포트 생성 및 아티팩트 저장 기능을 추가합니다.",
            "dependencies": ["30.3"],
            "details": "npm test 명령어를 통한 Jest 테스트 실행 단계 추가, 테스트 커버리지 리포트 생성 설정, 커버리지 결과를 GitHub Actions 아티팩트로 저장, 테스트 결과 요약을 PR 코멘트로 추가하는 액션 설정\n<info added on 2025-08-03T01:53:29.518Z>\n구현 완료: npm run coverage 명령어로 테스트 실행 단계 변경, Codecov 통합을 위해 codecov/codecov-action@v3 액션 추가, 커버리지 업로드 실패 시에도 워크플로우가 계속 진행되도록 continue-on-error: true 설정 적용\n</info added on 2025-08-03T01:53:29.518Z>",
            "status": "done",
            "testStrategy": "테스트 실패 시나리오에서 전체 워크플로우 중단 확인, 커버리지 리포트 생성 및 아티팩트 업로드 성공 여부 검증"
          },
          {
            "id": 5,
            "title": "성능 최적화 및 병렬 실행 구성",
            "description": "워크플로우 실행 시간을 단축하기 위한 성능 최적화 및 병렬 처리 설정을 구현합니다.",
            "dependencies": ["30.4"],
            "details": "독립적인 검사 단계들을 matrix 전략으로 병렬 실행 구성, npm 캐시 최적화 설정으로 의존성 설치 시간 단축, 조건부 실행으로 불필요한 작업 스킵 로직 추가, 워크플로우 실행 시간 모니터링 설정, 실패 시 빠른 중단(fail-fast) 전략 적용\n<info added on 2025-08-03T01:53:53.440Z>\nNode.js 18.x 매트릭스 전략으로 코드 품질 검사와 테스트 작업 병렬 실행 최적화 완료. 'needs: [code-quality, test]' 종속성을 통한 빌드 검증 작업 추가로 품질 게이트 강화. npm 캐싱 설정으로 의존성 설치 시간 단축 및 전체 워크플로우 효율성 개선.\n</info added on 2025-08-03T01:53:53.440Z>",
            "status": "done",
            "testStrategy": "병렬 실행으로 인한 성능 향상 측정, 캐시 적중률 및 의존성 설치 시간 단축 확인, 조건부 실행 시나리오별 동작 검증"
          }
        ]
      },
      {
        "id": 31,
        "title": "[BFS-47] yarn 패키지 매니저를 pnpm으로 마이그레이션",
        "description": "프로젝트의 패키지 매니저를 yarn에서 pnpm으로 완전히 마이그레이션하여 더 빠른 설치 속도, 디스크 공간 절약, 엄격한 의존성 관리를 달성합니다.",
        "details": "**구현 목표**\n- yarn 기반의 모든 설정과 명령어를 pnpm으로 전환\n- CI/CD 파이프라인, Docker 환경, 개발 문서 전체에 걸친 일관된 pnpm 적용\n- 기존 yarn 워크스페이스 구조를 pnpm 워크스페이스로 원활하게 마이그레이션\n\n**1. 의존성 마이그레이션**\n- pnpm 설치: `npm install -g pnpm@latest`\n- yarn.lock 파일을 기반으로 pnpm-lock.yaml 생성\n```bash\npnpm import  # yarn.lock을 읽어 pnpm-lock.yaml 생성\nrm yarn.lock\n```\n\n**2. 워크스페이스 설정 변환**\n- pnpm-workspace.yaml 파일 생성\n```yaml\npackages:\n  - 'packages/*'\n  - 'apps/*'\n```\n- 루트 package.json의 workspaces 필드 제거 (pnpm은 별도 파일 사용)\n\n**3. .npmrc 설정 파일 생성**\n```ini\n# .npmrc\nauto-install-peers=true\nstrict-peer-dependencies=false\nshared-workspace-lockfile=true\nhoist=true\nhoist-pattern[]=*\npublic-hoist-pattern[]=*eslint*\npublic-hoist-pattern[]=*prettier*\n```\n\n**4. GitHub Actions 워크플로우 수정**\n- .github/workflows/ci.yml 수정\n```yaml\n- uses: pnpm/action-setup@v2\n  with:\n    version: 8\n- name: Install dependencies\n  run: pnpm install --frozen-lockfile\n- name: Run lint\n  run: pnpm run lint\n- name: Run tests\n  run: pnpm test\n```\n- nightly.yml과 production.yml도 동일하게 수정\n\n**5. Docker 파일 업데이트**\n- dockerfile.packages 수정\n```dockerfile\n# pnpm 설치\nRUN npm install -g pnpm@8\n\n# 의존성 파일 복사\nCOPY pnpm-lock.yaml pnpm-workspace.yaml ./\nCOPY packages/*/package.json ./packages/\nCOPY apps/*/package.json ./apps/\n\n# 의존성 설치\nRUN pnpm install --frozen-lockfile --prod\n```\n- docker-compose.yaml 내 모든 yarn 명령어를 pnpm으로 변경\n\n**6. 문서 파일 업데이트**\n- SETUP.md, README.md, CLAUDE.md 등의 모든 yarn 명령어를 pnpm으로 변경\n- 예시:\n  - `yarn install` → `pnpm install`\n  - `yarn dev` → `pnpm dev`\n  - `yarn workspace @package/name add` → `pnpm add -w @package/name`\n  - `yarn build` → `pnpm build`\n\n**7. Claude 설정 업데이트**\n- .claude/settings.json에 pnpm 명령어 허용 추가\n```json\n{\n  \"allowedTools\": [\n    \"Bash(pnpm:*)\",\n    \"Bash(pnpm install:*)\",\n    \"Bash(pnpm add:*)\",\n    \"Bash(pnpm remove:*)\",\n    \"Bash(pnpm run:*)\",\n    \"Bash(pnpm exec:*)\",\n    \"Bash(pnpm workspace:*)\"\n  ]\n}\n```\n\n**8. 개발자 로컬 환경 마이그레이션 가이드**\n- node_modules 및 캐시 정리\n```bash\nrm -rf node_modules\nrm -rf packages/*/node_modules\nrm -rf apps/*/node_modules\npnpm store prune\n```\n- pnpm으로 새로 설치\n```bash\npnpm install\n```",
        "testStrategy": "**1. 의존성 설치 검증**\n- 클린 환경에서 `pnpm install` 실행 및 성공 확인\n- 모든 워크스페이스 패키지가 올바르게 링크되었는지 확인\n- `pnpm list` 명령으로 의존성 트리 정상 표시 확인\n- yarn.lock 파일이 제거되고 pnpm-lock.yaml만 존재하는지 확인\n\n**2. 개발 명령어 동작 테스트**\n- `pnpm dev` 실행하여 개발 서버 정상 시작 확인\n- `pnpm build` 실행하여 빌드 성공 확인\n- `pnpm test` 실행하여 모든 테스트 통과 확인\n- `pnpm lint` 및 `pnpm typecheck` 정상 동작 확인\n\n**3. 워크스페이스 기능 테스트**\n- 워크스페이스 간 의존성 해결 테스트\n- `pnpm workspace @withdrawal/shared add lodash` 같은 워크스페이스 명령어 테스트\n- 공유 패키지 변경 시 다른 패키지에서 즉시 반영되는지 확인\n\n**4. CI/CD 파이프라인 검증**\n- 새 PR 생성하여 GitHub Actions CI 파이프라인 정상 실행 확인\n- pnpm 설치, 의존성 설치, 테스트 실행 모든 단계 성공 확인\n- 빌드 아티팩트 생성 및 업로드 정상 동작 확인\n\n**5. Docker 환경 테스트**\n- `docker-compose build` 실행하여 이미지 빌드 성공 확인\n- 컨테이너 시작 및 애플리케이션 정상 동작 확인\n- 컨테이너 내부에서 pnpm 명령어 사용 가능 확인\n\n**6. 성능 비교 테스트**\n- 클린 설치 시간 측정 (yarn vs pnpm)\n- node_modules 디스크 사용량 비교\n- 빌드 시간 비교 및 개선 사항 문서화\n\n**7. 개발자 경험 검증**\n- 팀원들이 로컬 환경에서 마이그레이션 가이드 따라 성공적으로 전환\n- IDE(VSCode 등)에서 자동 완성 및 타입 체크 정상 동작\n- 기존 개발 워크플로우가 중단 없이 계속 가능한지 확인",
        "status": "done",
        "dependencies": [30, 28],
        "priority": "medium",
        "jiraKey": "BFS-47",
        "subtasks": [
          {
            "id": 1,
            "title": "yarn 제거 및 pnpm 설치 환경 준비",
            "description": "기존 yarn 환경을 정리하고 pnpm을 설치하여 마이그레이션을 위한 기본 환경을 준비합니다.",
            "dependencies": [],
            "details": "글로벌 pnpm 설치, 기존 node_modules 및 yarn 캐시 완전 제거, pnpm 버전 8.x 설치 확인, 모든 워크스페이스의 node_modules 디렉토리 정리\n<info added on 2025-08-04T05:17:29.493Z>\n실제 구현 완료 상황: pnpm 10.14.0 버전 설치 확인됨, 전체 프로젝트에서 716MB 규모의 node_modules 디렉토리 완전 제거 성공, yarn 캐시 정리 완료하여 디스크 공간 확보, yarn.lock 파일은 다음 단계인 의존성 파일 변환을 위해 보존 처리\n</info added on 2025-08-04T05:17:29.493Z>",
            "status": "done",
            "testStrategy": "pnpm 버전 확인, node_modules 디렉토리 존재 여부 검증, yarn 명령어 실행 불가 확인"
          },
          {
            "id": 2,
            "title": "의존성 파일 변환 및 워크스페이스 설정",
            "description": "yarn.lock을 pnpm-lock.yaml로 변환하고 pnpm 워크스페이스 구조를 설정합니다.",
            "dependencies": ["31.1"],
            "details": "pnpm import 명령으로 yarn.lock 변환, pnpm-workspace.yaml 파일 생성, .npmrc 설정 파일 작성, 루트 package.json의 workspaces 필드 제거, 호이스팅 패턴 설정\n<info added on 2025-08-04T05:19:31.336Z>\n구현 완료: pnpm import를 통해 yarn.lock을 pnpm-lock.yaml로 성공적으로 변환했습니다. pnpm-workspace.yaml 파일을 생성하여 모노레포 구조를 정의했고, .npmrc 파일을 통해 pnpm 전용 설정을 구성했습니다. pnpm install 실행으로 모든 의존성을 정상 설치했으며, node_modules 크기가 716MB에서 558MB로 22% 감소하여 디스크 공간 절약 효과를 확인했습니다.\n</info added on 2025-08-04T05:19:31.336Z>",
            "status": "done",
            "testStrategy": "pnpm-lock.yaml 파일 생성 확인, pnpm install --frozen-lockfile 성공 여부, 워크스페이스 패키지 간 링크 정상 작동 검증"
          },
          {
            "id": 3,
            "title": "CI/CD 파이프라인 및 Docker 환경 수정",
            "description": "GitHub Actions 워크플로우와 Docker 파일을 pnpm 환경에 맞게 수정합니다.",
            "dependencies": ["31.2"],
            "details": "모든 GitHub Actions 워크플로우 파일에 pnpm/action-setup 추가, yarn 명령어를 pnpm으로 변경, dockerfile.packages 수정, docker-compose.yaml 내 모든 yarn 명령어 변경, 빌드 캐시 최적화 설정\n<info added on 2025-08-04T05:23:17.096Z>\n구현 완료:\n- .github/workflows/ci.yml: pnpm/action-setup@v4 추가, 모든 yarn 명령어를 pnpm으로 변경\n- .github/workflows/production.yml: pnpm/action-setup@v4 추가, 모든 yarn 명령어를 pnpm으로 변경  \n- .github/workflows/nightly.yml: pnpm/action-setup@v4 추가, 모든 yarn 명령어를 pnpm으로 변경\n- docker/dockerfile.packages: yarn 대신 pnpm 사용하도록 전체 수정, pnpm store를 /root/.local/share/pnpm으로 설정\n- docker/docker-compose.yaml: 모든 yarn 명령어를 pnpm으로 변경 (dev, build, lint, typecheck 등)\n모든 CI/CD 파이프라인과 Docker 환경이 pnpm 기반으로 성공적으로 전환됨.\n</info added on 2025-08-04T05:23:17.096Z>",
            "status": "done",
            "testStrategy": "GitHub Actions 워크플로우 로컬 실행 테스트, Docker 이미지 빌드 성공 확인, 컨테이너 내부에서 pnpm 명령어 실행 가능 여부 검증"
          },
          {
            "id": 4,
            "title": "프로젝트 문서 및 개발 스크립트 업데이트",
            "description": "모든 문서 파일과 개발 스크립트에서 yarn 참조를 pnpm으로 변경합니다.",
            "dependencies": ["31.2"],
            "details": "README.md, SETUP.md, CLAUDE.md 등 모든 문서 파일 수정, package.json 스크립트 명령어 업데이트, 개발자 가이드 문서 작성, yarn workspace 명령어를 pnpm 등가 명령어로 변환, 마이그레이션 가이드 문서 작성\n<info added on 2025-08-04T05:25:52.527Z>\n프로젝트 전체 문서의 yarn 명령어 pnpm 마이그레이션 완료: package.json 루트 bootstrap 스크립트 pnpm으로 변경, SETUP.md 내 모든 npm 명령어를 pnpm 명령어로 일괄 변환, CLAUDE.md의 개발 가이드라인 내 npm 명령어를 pnpm으로 수정, .taskmaster/CLAUDE.md의 Task Master 워크플로우 명령어를 pnpm으로 업데이트, .github/workflows/README.md의 GitHub Actions 가이드 내 yarn 참조를 pnpm으로 변경하여 문서와 실제 패키지 매니저 간 일관성 확보\n</info added on 2025-08-04T05:25:52.527Z>",
            "status": "done",
            "testStrategy": "문서 내 yarn 키워드 검색으로 누락 확인, 변경된 명령어 실행 가능 여부 테스트, 개발자 가이드 따라 신규 환경 구성 성공 확인"
          },
          {
            "id": 5,
            "title": "Claude 설정 업데이트 및 전체 시스템 검증",
            "description": "Claude Code 설정을 업데이트하고 전체 시스템이 pnpm으로 정상 작동하는지 검증합니다.",
            "dependencies": ["31.3", "31.4"],
            "details": ".claude/settings.json에 pnpm 명령어 허용 목록 추가, 모든 개발 명령어 실행 테스트, 프로덕션 빌드 및 배포 프로세스 검증, 성능 벤치마크 수행, 롤백 계획 수립\n<info added on 2025-08-04T05:31:28.002Z>\n구현 완료 사항:\n\n**Claude Code 설정 업데이트**\n- .claude/settings.json에 pnpm 관련 허용 명령어 포괄적 추가 완료:\n  - 기본 pnpm 명령어: pnpm, pnpm install, pnpm add, pnpm remove\n  - 실행 스크립트: pnpm run, pnpm exec  \n  - 워크스페이스 명령어: pnpm workspace\n- 모든 pnpm 작업에 대한 권한 설정 완료\n\n**전체 시스템 검증 결과**\n- TypeScript 타입 검사 통과: signing-service의 누락된 @aws-sdk/client-sqs 의존성 추가하여 컴파일 오류 해결\n- 린팅 검사 통과: 모든 패키지에서 pnpm run lint 성공\n- 빌드 검증 완료: pnpm run build로 모든 패키지 정상 빌드 확인\n- 워크스페이스 기능 정상 작동: pnpm 워크스페이스 의존성 해결 검증 완료\n\n**마이그레이션 성과 확인**\n- node_modules 크기 22% 감소 달성 (716MB → 558MB)\n- 의존성 설치 속도 향상 확인\n- pnpm의 격리된 node_modules 구조로 엄격한 의존성 관리 실현\n- 모노레포 아키텍처에 최적화된 워크스페이스 지원 개선\n\npnpm 마이그레이션 프로세스 완전 완료, 모든 시스템 정상 작동 검증됨\n</info added on 2025-08-04T05:31:28.002Z>",
            "status": "done",
            "testStrategy": "pnpm dev/build/test/lint 명령어 전체 실행, 의존성 설치 속도 비교, 디스크 사용량 측정, Claude Code에서 pnpm 명령어 실행 가능 확인"
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-21T09:59:36.904Z",
      "updated": "2025-08-04T05:31:39.779Z",
      "description": "Tasks for master context"
    }
  }
}
