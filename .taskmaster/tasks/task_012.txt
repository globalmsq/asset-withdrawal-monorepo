# Task ID: 12
# Title: [BFS-5] tx-broadcaster 서비스 구현
# Status: in-progress
# Dependencies: 11
# Priority: high
# Description: 서명된 트랜잭션을 Polygon 네트워크에 브로드캐스트하고 database 패키지를 통해 트랜잭션 상태를 직접 관리하는 서비스 개발
# Details:
Nx를 사용하여 tx-broadcaster 앱 생성 (nx g @nx/node:app tx-broadcaster), signed-tx-queue에서 SQS 메시지 폴링, database 패키지를 통한 직접적인 데이터베이스 트랜잭션 상태 관리, Ethers.js v6를 사용하여 Polygon 네트워크 브로드캐스트, 트랜잭션 상태를 SIGNED → BROADCASTING → BROADCASTED/FAILED로 업데이트, txHash, broadcastedAt, blockNumber, 에러 메시지 저장, nonce 충돌 감지 및 DLQ 처리, RPC 실패 시 지수 백오프 재시도 로직, 브로드캐스트 성공 후 tx-monitor-queue에 메시지 전송, 배치 트랜잭션의 경우 batchId로 관련 트랜잭션들 일괄 상태 업데이트

# Test Strategy:
정상 브로드캐스트 플로우 테스트, nonce 충돌 시나리오 테스트, RPC 실패 및 재시도 테스트, 재시도 한도 초과 시 DLQ 처리 테스트, 단일/배치 트랜잭션 브로드캐스트 테스트, database 패키지를 통한 상태 업데이트 테스트, 통합 테스트 환경에서 10개 테스트 케이스 실행 검증

# Subtasks:
## 1. Nx를 사용하여 tx-broadcaster 앱 생성 및 기본 구조 설정 [done]
### Dependencies: None
### Description: Nx CLI를 사용하여 새로운 Node.js 애플리케이션을 생성하고 기본 프로젝트 구조를 설정합니다 [Updated: 2025. 8. 4.]
### Details:
nx g @nx/node:app tx-broadcaster 명령으로 앱 생성, TypeScript 설정, Express 서버 기본 구조 생성, 환경 변수 설정 (.env 파일), Docker 설정 추가, 포트 3003 할당
<info added on 2025-08-04T09:03:24.574Z>
Task 12 subtitle을 '[BFS-48] Nx를 사용하여 tx-broadcaster 앱 생성 및 기본 구조 설정'로 변경
</info added on 2025-08-04T09:03:24.574Z>
<info added on 2025-08-04T09:15:32.672Z>
완료: 앱 생성 및 기본 구조 설정 완료. Express 웹 서버 구조, TypeScript 빌드 구성, 헬스체크 엔드포인트, 보안 미들웨어(helmet, cors), 환경 변수 설정 파일, README.md 문서, Docker 설정 포함. 포트 3003으로 서버 설정. 린트 및 타입 체크 통과 확인. 다음 단계인 SQS 폴링 로직 구현을 위한 기반 구조 완료.
</info added on 2025-08-04T09:15:32.672Z>

## 2. SQS 폴링 로직 구현 및 signed-tx-queue 연결 [done]
### Dependencies: 12.1
### Description: signed-tx-queue에서 서명된 트랜잭션 메시지를 지속적으로 폴링하는 로직을 구현합니다 [Updated: 2025. 8. 4.]
### Details:
QueueConsumer 클래스 구현, signed-tx-queue URL 설정, 메시지 수신 및 파싱 로직, visibility timeout 설정 (300초), 메시지 삭제 처리, 에러 발생 시 DLQ 전송 로직
<info added on 2025-08-04T09:04:29.412Z>
제목이 '[BFS-49] SQS 폴링 로직 구현 및 signed-tx-queue 연결'로 변경되었습니다. 이는 BFS-49 작업 키를 참조하여 작업의 식별성을 개선하고 Jira 연동을 위한 표준 명명 규칙을 준수합니다.
</info added on 2025-08-04T09:04:29.412Z>
<info added on 2025-08-04T09:34:01.455Z>
tx-broadcaster 서비스의 전체 SQS 폴링 및 메시지 처리 시스템이 완료되었습니다. SQS Worker를 통한 메시지 폴링 및 처리, Redis 기반 중복 방지 시스템, Express 서버와 워커의 병렬 실행 구조, ethers.js 기반 블록체인 브로드캐스팅, 포괄적인 에러 처리 및 재시도 메커니즘이 모두 구현되었습니다. 이로써 signed-tx-queue에서 메시지를 수신하여 broadcast-tx-queue로 전달하는 완전한 파이프라인이 구축되었습니다.
</info added on 2025-08-04T09:34:01.455Z>

## 3. Polygon 네트워크 브로드캐스트 로직 구현 [done]
### Dependencies: 12.2
### Description: Ethers.js v6를 사용하여 서명된 트랜잭션을 Polygon 네트워크에 브로드캐스트하는 서비스를 구현합니다 [Updated: 2025. 8. 4.]
### Details:
BroadcastService 클래스 구현, Ethers.js v6 Provider 설정 (Polygon RPC), sendRawTransaction 메서드 구현, 트랜잭션 해시 반환 처리, 네트워크별 설정 관리 (Amoy, Mainnet)
<info added on 2025-08-04T09:04:46.664Z>
제목이 '[BFS-50] Polygon 네트워크 브로드캐스트 로직 구현'로 변경됨. 이는 상위 작업 BFS-52의 하위 기능으로 Polygon 네트워크 전용 브로드캐스트 로직 구현에 집중하는 것을 명확히 함.
</info added on 2025-08-04T09:04:46.664Z>

## 4. TransactionService 클래스 구현 및 상태 관리 로직 [done]
### Dependencies: 12.3
### Description: 트랜잭션 라이프사이클 문서의 3단계 상태 전이를 위한 TransactionService 클래스를 구현하고 database 패키지를 연동합니다
### Details:
TransactionService 클래스 구현: updateToBroadcasting(requestId) - SIGNED → BROADCASTING 상태 전이, updateToBroadcasted(requestId, txHash, broadcastedAt) - BROADCASTING → BROADCASTED 상태 전이, updateToFailed(requestId, errorMessage) - 실패 시 FAILED 상태 처리, updateBatchToBroadcasting/Broadcasted(batchId) - 배치 트랜잭션 일괄 상태 관리, WithdrawalRequest.status, txHash, broadcastedAt 필드 업데이트, SignedSingleTransaction/SignedBatchTransaction 테이블 연동
<info added on 2025-08-04T14:34:18.209Z>
완료 상세사항:

**TransactionService 클래스 구현 완료**
- updateToBroadcasting(): SIGNED → BROADCASTING 상태 전이, 타임스탬프 기록
- updateToBroadcasted(): BROADCASTING → BROADCASTED 상태 전이, txHash와 broadcastedAt 필드 저장
- updateToFailed(): 브로드캐스트 실패 시 FAILED 상태 처리, 에러 메시지 저장
- updateBatchToBroadcasting/Broadcasted(): 배치 트랜잭션 일괄 상태 관리 메서드

**TransactionBroadcaster 연동 완료**
- broadcastTransaction() 메서드에 상태 관리 로직 완전 통합
- 브로드캐스트 전후 상태 전이 자동화 (SIGNED → BROADCASTING → BROADCASTED/FAILED)
- 에러 핸들링 및 상태 롤백 로직 포함

**데이터베이스 연동 완료**
- database 패키지 의존성 정상 추가, Prisma 클라이언트 연결 확인
- WithdrawalRequest, SignedSingleTransaction, SignedBatchTransaction 테이블 모든 필드 업데이트 지원
- 단일/배치 트랜잭션 시나리오 모두 검증 완료

**검증 및 테스트**
- 트랜잭션 라이프사이클 3단계 정상 플로우 구현 완성
- 문서 정의와 상태 전이 로직 정확히 일치 확인
- 모든 에러 시나리오 처리 및 데이터 무결성 보장
</info added on 2025-08-04T14:34:18.209Z>

## 5. TransactionBroadcaster 클래스와 상태 관리 통합 [done]
### Dependencies: 12.4
### Description: TransactionBroadcaster 클래스의 broadcastTransaction() 메서드에 상태 관리 로직을 통합하여 자동화된 상태 전이를 구현합니다
### Details:
broadcastTransaction() 메서드에 상태 관리 로직 통합, 브로드캐스트 전후 상태 업데이트 자동화 (SIGNED → BROADCASTING → BROADCASTED), 성공/실패 시나리오별 적절한 상태 전이 처리, TransactionService와 BroadcastService 간 협력 구조 구현, 트랜잭션 라이프사이클 문서의 정상 플로우 완전 구현

## 6. tx-monitor-queue 메시지 전송 로직 구현 [done]
### Dependencies: 12.5
### Description: 브로드캐스트 성공 후 tx-monitor-queue에 메시지를 전송하는 로직을 구현합니다
### Details:
tx-monitor-queue 연결 설정, 브로드캐스트 성공 시 모니터링 메시지 전송, 메시지 포맷 정의 (txHash, broadcastedAt, blockNumber 포함), 단일 및 배치 트랜잭션 메시지 처리, 메시지 전송 실패 시 재시도 로직

## 7. 에러 처리 및 재시도 로직 구현 [done]
### Dependencies: 12.6
### Description: nonce 충돌, RPC 실패 등의 에러를 처리하고 지수 백오프 재시도 로직을 구현합니다
### Details:
RetryService 구현 (지수 백오프 알고리즘), nonce 충돌 감지 및 처리 로직, RPC 에러 분류 및 재시도 가능 여부 판단, 최대 재시도 횟수 설정 (5회), 재시도 실패 시 FAILED 상태 및 DLQ 전송, 에러별 모니터링 메트릭 수집, database를 통한 에러 메시지 저장

## 8. tx-broadcaster 서비스 통합 테스트 실행 [done]
### Dependencies: 12.7
### Description: Docker+LocalStack+SQS Admin UI+Redis+Hardhat 환경에서 10개 테스트 케이스를 통해 tx-broadcaster 서비스의 전체 기능을 종합 검증합니다
### Details:
테스트 환경 구성: Docker Compose로 서비스 실행, LocalStack(SQS), SQS Admin UI(포트 3999), Redis Insight(포트 8001), Hardhat 노드(포트 8545)

10개 테스트 케이스 실행:
- TC-01: 정상 브로드캐스트 플로우 검증
- TC-02: 네트워크 오류 시 재시도 로직 검증
- TC-03: Nonce 충돌 감지 및 처리 검증
- TC-04: 중복 메시지 방지 시스템 검증
- TC-05: 통합 메시지 처리 파이프라인 검증
- TC-06: 배치 트랜잭션 처리 검증
- TC-07: DLQ(Dead Letter Queue) 처리 검증
- TC-08: 큐 간 통신 정상성 검증
- TC-09: 체인ID 검증 로직 테스트
- TC-10: 통계 수집 및 모니터링 검증

검증 체크리스트:
1. 서비스 정상 실행 확인
2. 테스트 메시지 전송 및 수신 확인
3. 애플리케이션 로그를 통한 처리 과정 확인
4. Redis 상태 및 중복 방지 동작 확인
5. SQS 큐 메시지 처리 상태 확인
6. 에러 처리 및 상태 전이 확인
7. 재시도 로직 동작 확인
8. DLQ로 메시지 전송 확인
9. 통계 데이터 수집 확인
10. 전체 파이프라인 통합 동작 검증

## 9. Docker integration [done]
### Dependencies: None
### Description: Update Dockerfile and docker-compose configuration for tx-broadcaster service integration
### Details:


## 10. Nonce 순서 보장 시스템 구현 [pending]
### Dependencies: 12.12
### Description: NonceManager 서비스를 생성하여 주소별 nonce 추적 및 관리, Redis 기반 상태 관리, nonce 갭 감지 및 복구 메커니즘을 구현합니다.
### Details:
**구현 목표**
- 블록체인 트랜잭션의 nonce 순서를 보장하는 중앙화된 관리 시스템 구축
- Redis를 활용한 고성능 nonce 상태 관리 및 동시성 제어
- nonce 갭 발생 시 자동 감지 및 복구 메커니즘으로 트랜잭션 안정성 확보

**1. NonceManager 서비스 생성**
- `packages/shared/src/services/nonce-manager.service.ts` 생성
- 주소별 nonce 추적을 위한 인터페이스 및 클래스 구현
```typescript
interface NonceManagerConfig {
  redisUrl: string;
  gapDetectionInterval: number;
  maxGapSize: number;
  recoveryTimeoutMs: number;
}

class NonceManager {
  constructor(
    private redis: Redis,
    private logger: Logger,
    private config: NonceManagerConfig
  ) {}

  async getNextNonce(address: string): Promise<number>;
  async reserveNonce(address: string, txHash: string): Promise<number>;
  async confirmNonce(address: string, nonce: number, txHash: string): Promise<void>;
  async detectGaps(): Promise<NonceGap[]>;
  async recoverGap(address: string, gap: NonceGap): Promise<void>;
}
```

**2. Redis 기반 상태 관리**
- 주소별 nonce 상태를 Redis Hash로 관리
- Key 구조: `nonce:{address}` → {current: number, pending: Set<number>, confirmed: Set<number>}
- Redis 트랜잭션(MULTI/EXEC)을 사용한 원자적 nonce 할당
- TTL 설정을 통한 오래된 nonce 데이터 자동 정리

**3. Nonce 갭 감지 시스템**
- 주기적으로(기본 30초) 모든 주소의 nonce 상태 스캔
- pending과 confirmed nonce 사이의 갭 식별
- 임계값(기본 5개) 이상의 갭 발견 시 알림 및 복구 트리거
```typescript
interface NonceGap {
  address: string;
  expectedNonce: number;
  actualNonce: number;
  gapSize: number;
  detectedAt: Date;
}
```

**4. 복구 메커니즘 구현**
- 갭이 발견된 nonce에 대한 블록체인 상태 조회
- 트랜잭션이 실제로 실패했는지 확인 후 nonce 재할당
- 복구 불가능한 경우 DLQ로 메시지 전송 및 수동 처리 요청
- 복구 과정 중 해당 주소의 새로운 트랜잭션 처리 일시 중단

**5. 동시성 제어 및 락 메커니즘**
- Redis 분산 락을 사용한 주소별 nonce 할당 동시성 제어
- Lock timeout 설정을 통한 데드락 방지
- Lock 획득 실패 시 재시도 로직 구현

## 11. 트랜잭션 큐 순서 보장 구현 [pending]
### Dependencies: 12.12
### Description: 같은 주소의 트랜잭션은 nonce 순서로 순차 처리하고, 다른 주소의 트랜잭션은 병렬 처리할 수 있는 TransactionQueue 서비스를 구현하여 트랜잭션 처리 효율성과 블록체인 규칙 준수를 보장합니다.
### Details:
**구현 목표**
- 주소별 트랜잭션 큐를 분리하여 동일 주소 내 순차 처리와 주소간 병렬 처리 구현
- nonce 기반 트랜잭션 순서 보장으로 블록체인 네트워크 규칙 준수
- 큐 상태 모니터링과 데드락 방지 메커니즘 구현

**1. TransactionQueue 서비스 생성**
- `packages/shared/src/services/transaction-queue.service.ts` 생성
- 주소별 큐 관리를 위한 Map<string, Transaction[]> 구조 구현
- 각 주소별 처리 상태 추적 (processing, idle)
```typescript
interface QueuedTransaction {
  id: string;
  fromAddress: string;
  nonce: number;
  priority: number;
  createdAt: Date;
  transaction: SignedBatchTransaction;
}

class TransactionQueue {
  private addressQueues: Map<string, QueuedTransaction[]>;
  private processingAddresses: Set<string>;
  private logger: Logger;
}
```

**2. 주소별 큐 관리 시스템**
- enqueue() 메서드: 트랜잭션을 해당 주소 큐에 nonce 순서대로 삽입
- dequeue() 메서드: 처리 중이지 않은 주소의 다음 트랜잭션 반환
- nonce 순서 보장을 위한 정렬 알고리즘 구현
- 주소별 처리 락 메커니즘으로 동시 처리 방지

**3. 병렬 처리 최적화**
- getNextAvailableTransaction(): 처리 가능한 주소의 다음 트랜잭션 선택
- 라운드로빈 방식으로 주소간 공평한 처리 기회 제공
- 큐 길이 기반 우선순위 조정 (긴 큐 우선 처리)
- 타임아웃 기반 데드락 감지 및 해제

**4. tx-broadcaster와의 통합**
- signing-service에서 서명된 트랜잭션을 TransactionQueue에 추가
- tx-broadcaster에서 큐로부터 순차적으로 트랜잭션 가져와 브로드캐스트
- 처리 완료 시 해당 주소 락 해제 및 다음 트랜잭션 활성화
- 실패한 트랜잭션의 재시도 및 DLQ 처리

## 12. Nonce 갭 복구 전략 구현 [pending]
### Dependencies: None
### Description: 트랜잭션 nonce 갭 발생 시 자동 복구를 위한 실패 재시도, 더미 트랜잭션 갭 채우기, 복구 불가 시 관리자 알림, 모니터링 메트릭 시스템을 구현합니다.
### Details:
**구현 목표**
- Nonce 갭 발생 시 자동 감지 및 복구 메커니즘 구현
- 다단계 복구 전략으로 시스템 안정성 확보
- 복구 불가능한 상황에 대한 알림 및 모니터링 체계 구축

**1. NonceGapRecoveryService 구현**
- `packages/shared/src/services/nonce-gap-recovery.service.ts` 생성
- 갭 감지 로직: 연속된 nonce 값 사이의 누락 구간 식별
- 복구 전략 인터페이스 정의
```typescript
interface RecoveryStrategy {
  canHandle(gap: NonceGap): boolean;
  execute(gap: NonceGap): Promise<RecoveryResult>;
  priority: number;
}
```

**2. 복구 전략 구현**
- RetryStrategy: 실패한 트랜잭션 재전송 시도 (최대 3회)
- DummyTransactionStrategy: 갭 구간에 더미 트랜잭션 전송으로 갭 채우기
- AlarmStrategy: 복구 불가 시 관리자 알림 발송
- 각 전략별 우선순위 및 조건 설정

**3. 모니터링 메트릭 시스템**
- Prometheus 메트릭 추가: nonce_gap_detected, recovery_attempts, recovery_success_rate
- CloudWatch 알림 설정: 갭 발생 빈도, 복구 실패율 임계값 모니터링
- 대시보드 구성: 실시간 nonce 상태 및 복구 통계 시각화

**4. tx-broadcaster와 통합**
- NonceManager에 갭 복구 로직 통합
- 브로드캐스트 실패 시 자동 갭 복구 시도
- 복구 진행 상황 로깅 및 상태 추적

